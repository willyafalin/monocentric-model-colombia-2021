{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6869d41-b501-479f-baab-f79732839a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "On va ici essayer d'étendre notre étude à l'intérieur des territoires, essayer de déceler des structures urbaines intra-territoriales. L'intérêt étant qu'on souhaite contourner le problème du manque de données cabecera pour le département de la capitale Bogota. La seconde raison est d'exploiter la richesse des données Colombienne, notamment la variable Utilrank qui est une spécificité Colombienne, pour essayer de mieux comprendre la structure urbaine à l'intérieur des territoires. On va étudier spécifiquement Bogota et voir si sa structure suit l'hypothèse monocentrique.\n",
       "\n",
       "En termes de méthodes, rien de nouveau : on sélectionne les variables d'amenités avec un LASSO. Meme chose que dans 4_lasso, sauf que l'échantillon est réduit et on n'a plus la variable de territoire. Ensuite, on regarde les coefficients et p-valeurs de Utilrank.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "markdown = \"\"\"\n",
    "On va ici essayer d'étendre notre étude à l'intérieur des territoires, essayer de déceler des structures urbaines intra-territoriales. L'intérêt étant qu'on souhaite contourner le problème du manque de données cabecera pour le département de la capitale Bogota. La seconde raison est d'exploiter la richesse des données Colombienne, notamment la variable Utilrank qui est une spécificité Colombienne, pour essayer de mieux comprendre la structure urbaine à l'intérieur des territoires. On va étudier spécifiquement Bogota et voir si sa structure suit l'hypothèse monocentrique.\n",
    "\n",
    "En termes de méthodes, rien de nouveau : on sélectionne les variables d'amenités avec un LASSO. Meme chose que dans 4_lasso, sauf que l'échantillon est réduit et on n'a plus la variable de territoire. Ensuite, on regarde les coefficients et p-valeurs de Utilrank.\n",
    "\"\"\"\n",
    "display(Markdown(markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82c4bce7-b42c-4d7d-a21d-f39aa575cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "total_dataset_clean = pd.read_stata(\"data_base_enrichie_totalement_clean.dta\") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f57b107f-2709-4ff5-b56c-3a13850bef89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "745     2746.535202\n",
       "746     3721.893018\n",
       "747     3879.347831\n",
       "748     4219.963001\n",
       "749     3264.525349\n",
       "           ...     \n",
       "8477    4452.870790\n",
       "8478    3996.445507\n",
       "8479    2008.355425\n",
       "8480    4590.060261\n",
       "8486    5904.077240\n",
       "Name: fex_c_2011, Length: 723, dtype: float64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bogota = total_dataset_clean\n",
    "bogota['DPTO'] = pd.to_numeric(bogota['DPTO'], errors='coerce')\n",
    "bogota = bogota[bogota['DPTO']==11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "336ffc07-7efa-4ec3-b636-8edecf7ac82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# on relance une procedure LASSO sans la variable territory \n",
    "\n",
    "variables = ['level_educ','age', 'marital_status','gender', 'own_status','Numrooms', 'Numroomsleep', 'Sanserv1', 'Sanserv2', 'Garbdisp', 'Watserv', 'Kitchen', 'Fuelc',\n",
    "             'Phone_service', 'tvservice', 'Internet_service', 'Washing', 'Refrigerator', 'Blender', 'Stove',\n",
    "             'Oven', 'Microwave', 'Water_heater', 'ColorTV', 'Computer', 'AirCond', 'typeofbuilding', 'Stereo',\n",
    "             'Floor', 'Wallsmaterial','Garbcollectfreq','Dummyelec',\n",
    "             'Utilrank', 'Naturalgas', 'Sewage_system', 'Garbcollect', 'Aqueduct', 'Frequencewat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ca00553e-59cf-4cb8-83c0-205a37b32afc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables categorielles à preprocesser:\n",
      "['level_educ', 'marital_status', 'gender', 'own_status', 'Sanserv1', 'Sanserv2', 'Garbdisp', 'Watserv', 'Kitchen', 'Fuelc', 'Phone_service', 'tvservice', 'Internet_service', 'Washing', 'Refrigerator', 'Blender', 'Stove', 'Oven', 'Microwave', 'Water_heater', 'ColorTV', 'Computer', 'AirCond', 'typeofbuilding', 'Stereo', 'Floor', 'Wallsmaterial', 'Garbcollectfreq', 'Dummyelec', 'Utilrank', 'Naturalgas', 'Sewage_system', 'Garbcollect', 'Aqueduct', 'Frequencewat']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_educ_3.0</th>\n",
       "      <th>level_educ_4.0</th>\n",
       "      <th>level_educ_5.0</th>\n",
       "      <th>level_educ_6.0</th>\n",
       "      <th>marital_status_2.0</th>\n",
       "      <th>marital_status_3.0</th>\n",
       "      <th>marital_status_4.0</th>\n",
       "      <th>marital_status_5.0</th>\n",
       "      <th>gender_2.0</th>\n",
       "      <th>own_status_1</th>\n",
       "      <th>Sanserv2_2.0</th>\n",
       "      <th>Watserv_10.0</th>\n",
       "      <th>Kitchen_2.0</th>\n",
       "      <th>Kitchen_3.0</th>\n",
       "      <th>Kitchen_6.0</th>\n",
       "      <th>Fuelc_3.0</th>\n",
       "      <th>Fuelc_4.0</th>\n",
       "      <th>Fuelc_5.0</th>\n",
       "      <th>Phone_service_2.0</th>\n",
       "      <th>tvservice_2.0</th>\n",
       "      <th>Internet_service_2.0</th>\n",
       "      <th>Washing_2.0</th>\n",
       "      <th>Refrigerator_2.0</th>\n",
       "      <th>Blender_2.0</th>\n",
       "      <th>Stove_2.0</th>\n",
       "      <th>Oven_2.0</th>\n",
       "      <th>Microwave_2.0</th>\n",
       "      <th>Water_heater_2.0</th>\n",
       "      <th>ColorTV_2.0</th>\n",
       "      <th>Computer_2.0</th>\n",
       "      <th>AirCond_2.0</th>\n",
       "      <th>typeofbuilding_2.0</th>\n",
       "      <th>Stereo_2.0</th>\n",
       "      <th>Floor_3.0</th>\n",
       "      <th>Floor_4.0</th>\n",
       "      <th>Floor_5.0</th>\n",
       "      <th>Floor_6.0</th>\n",
       "      <th>Garbcollectfreq_3.0</th>\n",
       "      <th>Garbcollectfreq_4.0</th>\n",
       "      <th>Utilrank_2.0</th>\n",
       "      <th>Utilrank_3.0</th>\n",
       "      <th>Utilrank_4.0</th>\n",
       "      <th>Utilrank_5.0</th>\n",
       "      <th>Utilrank_6.0</th>\n",
       "      <th>Naturalgas_2.0</th>\n",
       "      <th>Frequencewat_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8478</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8479</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8480</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8486</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>723 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      level_educ_3.0  level_educ_4.0  level_educ_5.0  level_educ_6.0  \\\n",
       "745              0.0             0.0             0.0             1.0   \n",
       "746              1.0             0.0             0.0             0.0   \n",
       "747              0.0             0.0             1.0             0.0   \n",
       "748              0.0             0.0             0.0             1.0   \n",
       "749              0.0             0.0             1.0             0.0   \n",
       "...              ...             ...             ...             ...   \n",
       "8477             0.0             0.0             1.0             0.0   \n",
       "8478             0.0             1.0             0.0             0.0   \n",
       "8479             0.0             0.0             1.0             0.0   \n",
       "8480             0.0             0.0             1.0             0.0   \n",
       "8486             0.0             0.0             0.0             1.0   \n",
       "\n",
       "      marital_status_2.0  marital_status_3.0  marital_status_4.0  \\\n",
       "745                  0.0                 1.0                 0.0   \n",
       "746                  0.0                 0.0                 0.0   \n",
       "747                  1.0                 0.0                 0.0   \n",
       "748                  0.0                 0.0                 0.0   \n",
       "749                  1.0                 0.0                 0.0   \n",
       "...                  ...                 ...                 ...   \n",
       "8477                 0.0                 0.0                 0.0   \n",
       "8478                 0.0                 0.0                 1.0   \n",
       "8479                 1.0                 0.0                 0.0   \n",
       "8480                 1.0                 0.0                 0.0   \n",
       "8486                 1.0                 0.0                 0.0   \n",
       "\n",
       "      marital_status_5.0  gender_2.0  own_status_1  Sanserv2_2.0  \\\n",
       "745                  0.0         1.0           0.0           0.0   \n",
       "746                  0.0         1.0           0.0           0.0   \n",
       "747                  0.0         0.0           0.0           0.0   \n",
       "748                  0.0         0.0           1.0           0.0   \n",
       "749                  0.0         1.0           0.0           0.0   \n",
       "...                  ...         ...           ...           ...   \n",
       "8477                 0.0         1.0           0.0           0.0   \n",
       "8478                 0.0         0.0           0.0           0.0   \n",
       "8479                 0.0         0.0           0.0           0.0   \n",
       "8480                 0.0         0.0           0.0           0.0   \n",
       "8486                 0.0         0.0           0.0           0.0   \n",
       "\n",
       "      Watserv_10.0  Kitchen_2.0  Kitchen_3.0  Kitchen_6.0  Fuelc_3.0  \\\n",
       "745            0.0          0.0          0.0          0.0        1.0   \n",
       "746            0.0          0.0          0.0          0.0        1.0   \n",
       "747            0.0          0.0          0.0          0.0        1.0   \n",
       "748            0.0          0.0          0.0          0.0        1.0   \n",
       "749            0.0          0.0          0.0          0.0        1.0   \n",
       "...            ...          ...          ...          ...        ...   \n",
       "8477           0.0          0.0          0.0          0.0        1.0   \n",
       "8478           0.0          0.0          0.0          0.0        1.0   \n",
       "8479           0.0          0.0          0.0          0.0        1.0   \n",
       "8480           0.0          0.0          0.0          0.0        1.0   \n",
       "8486           0.0          0.0          0.0          0.0        1.0   \n",
       "\n",
       "      Fuelc_4.0  Fuelc_5.0  Phone_service_2.0  tvservice_2.0  \\\n",
       "745         0.0        0.0                1.0            0.0   \n",
       "746         0.0        0.0                1.0            1.0   \n",
       "747         0.0        0.0                1.0            0.0   \n",
       "748         0.0        0.0                1.0            0.0   \n",
       "749         0.0        0.0                0.0            1.0   \n",
       "...         ...        ...                ...            ...   \n",
       "8477        0.0        0.0                1.0            0.0   \n",
       "8478        0.0        0.0                1.0            0.0   \n",
       "8479        0.0        0.0                1.0            0.0   \n",
       "8480        0.0        0.0                1.0            0.0   \n",
       "8486        0.0        0.0                0.0            0.0   \n",
       "\n",
       "      Internet_service_2.0  Washing_2.0  Refrigerator_2.0  Blender_2.0  \\\n",
       "745                    0.0          0.0               0.0          0.0   \n",
       "746                    1.0          0.0               0.0          0.0   \n",
       "747                    0.0          1.0               0.0          1.0   \n",
       "748                    0.0          0.0               0.0          0.0   \n",
       "749                    0.0          1.0               0.0          0.0   \n",
       "...                    ...          ...               ...          ...   \n",
       "8477                   0.0          0.0               0.0          0.0   \n",
       "8478                   0.0          0.0               0.0          0.0   \n",
       "8479                   0.0          0.0               0.0          0.0   \n",
       "8480                   0.0          0.0               0.0          0.0   \n",
       "8486                   1.0          0.0               0.0          0.0   \n",
       "\n",
       "      Stove_2.0  Oven_2.0  Microwave_2.0  Water_heater_2.0  ColorTV_2.0  \\\n",
       "745         0.0       1.0            1.0               0.0          0.0   \n",
       "746         0.0       1.0            1.0               1.0          0.0   \n",
       "747         0.0       1.0            0.0               0.0          0.0   \n",
       "748         0.0       0.0            0.0               0.0          0.0   \n",
       "749         0.0       1.0            1.0               1.0          0.0   \n",
       "...         ...       ...            ...               ...          ...   \n",
       "8477        0.0       1.0            1.0               1.0          0.0   \n",
       "8478        0.0       1.0            1.0               0.0          0.0   \n",
       "8479        0.0       0.0            1.0               0.0          0.0   \n",
       "8480        0.0       1.0            0.0               1.0          0.0   \n",
       "8486        0.0       1.0            1.0               0.0          0.0   \n",
       "\n",
       "      Computer_2.0  AirCond_2.0  typeofbuilding_2.0  Stereo_2.0  Floor_3.0  \\\n",
       "745            0.0          1.0                 1.0         0.0        0.0   \n",
       "746            1.0          1.0                 1.0         0.0        0.0   \n",
       "747            1.0          1.0                 1.0         1.0        0.0   \n",
       "748            0.0          1.0                 0.0         1.0        0.0   \n",
       "749            1.0          1.0                 1.0         0.0        0.0   \n",
       "...            ...          ...                 ...         ...        ...   \n",
       "8477           1.0          1.0                 1.0         1.0        0.0   \n",
       "8478           1.0          1.0                 1.0         1.0        0.0   \n",
       "8479           1.0          1.0                 1.0         1.0        0.0   \n",
       "8480           0.0          1.0                 1.0         0.0        0.0   \n",
       "8486           1.0          1.0                 1.0         1.0        0.0   \n",
       "\n",
       "      Floor_4.0  Floor_5.0  Floor_6.0  Garbcollectfreq_3.0  \\\n",
       "745         1.0        0.0        0.0                  1.0   \n",
       "746         1.0        0.0        0.0                  1.0   \n",
       "747         1.0        0.0        0.0                  1.0   \n",
       "748         1.0        0.0        0.0                  1.0   \n",
       "749         0.0        0.0        0.0                  1.0   \n",
       "...         ...        ...        ...                  ...   \n",
       "8477        1.0        0.0        0.0                  1.0   \n",
       "8478        1.0        0.0        0.0                  1.0   \n",
       "8479        1.0        0.0        0.0                  1.0   \n",
       "8480        1.0        0.0        0.0                  1.0   \n",
       "8486        1.0        0.0        0.0                  1.0   \n",
       "\n",
       "      Garbcollectfreq_4.0  Utilrank_2.0  Utilrank_3.0  Utilrank_4.0  \\\n",
       "745                   0.0           0.0           1.0           0.0   \n",
       "746                   0.0           0.0           0.0           0.0   \n",
       "747                   0.0           0.0           0.0           0.0   \n",
       "748                   0.0           0.0           1.0           0.0   \n",
       "749                   0.0           0.0           0.0           0.0   \n",
       "...                   ...           ...           ...           ...   \n",
       "8477                  0.0           1.0           0.0           0.0   \n",
       "8478                  0.0           0.0           1.0           0.0   \n",
       "8479                  0.0           1.0           0.0           0.0   \n",
       "8480                  0.0           1.0           0.0           0.0   \n",
       "8486                  0.0           0.0           1.0           0.0   \n",
       "\n",
       "      Utilrank_5.0  Utilrank_6.0  Naturalgas_2.0  Frequencewat_2.0  \n",
       "745            0.0           0.0             0.0               1.0  \n",
       "746            0.0           0.0             0.0               1.0  \n",
       "747            0.0           0.0             0.0               1.0  \n",
       "748            0.0           0.0             0.0               1.0  \n",
       "749            0.0           0.0             0.0               1.0  \n",
       "...            ...           ...             ...               ...  \n",
       "8477           0.0           0.0             0.0               1.0  \n",
       "8478           0.0           0.0             0.0               1.0  \n",
       "8479           0.0           0.0             0.0               1.0  \n",
       "8480           0.0           0.0             0.0               1.0  \n",
       "8486           0.0           0.0             0.0               1.0  \n",
       "\n",
       "[723 rows x 46 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ici, on cherche toutes les variables categorielles qui demandent une transformation en dummy variable \n",
    "\n",
    "#value_counts_dict = {} #si on veut les value counts\n",
    "value_counts_dict = []\n",
    "\n",
    "# boucle qui filtre les var categorielles (sans prendre les var qu'on ne veut pas transformer)\n",
    "for col in variables:\n",
    "    unique_values_count = bogota[col].nunique()\n",
    "    if unique_values_count and col not in ['Numrooms', 'Numroomsleep','age']:\n",
    "        #value_counts_dict[col] = bogota[col].value_counts()   #pour avoir le compte. on a juste besoin du nom des vars \n",
    "        value_counts_dict.append(col)\n",
    "print(\"Variables categorielles à preprocesser:\")\n",
    "print(value_counts_dict)\n",
    "data = bogota[value_counts_dict]\n",
    "\n",
    "\n",
    "for column in value_counts_dict: #on cree les dummies puis on concatene\n",
    "    dummies = pd.get_dummies(data[column], prefix=column, dtype=float, drop_first=True)\n",
    "    data = pd.concat([data, dummies], axis=1)\n",
    "\n",
    "data = data.drop(value_counts_dict, axis=1) #base de preprocessing clean, il manque les variables \n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8fa6e03-3ccb-4a3c-9eaa-4056b441a3ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Numrooms</th>\n",
       "      <th>Numroomsleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>723 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Numrooms  Numroomsleep\n",
       "0    0.428571           0.4\n",
       "1    0.142857           0.0\n",
       "2    0.000000           0.0\n",
       "3    0.428571           0.2\n",
       "4    0.142857           0.0\n",
       "..        ...           ...\n",
       "718  0.285714           0.2\n",
       "719  0.000000           0.0\n",
       "720  0.428571           0.4\n",
       "721  0.285714           0.2\n",
       "722  0.285714           0.2\n",
       "\n",
       "[723 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# on transforme nos variables continues \n",
    "scaler = MinMaxScaler()\n",
    "data_preprocess = scaler.fit_transform(bogota[['Numrooms', 'Numroomsleep']])\n",
    "data_preprocess = pd.DataFrame(data_preprocess, columns=['Numrooms', 'Numroomsleep'])\n",
    "data_preprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "98b528b0-f05c-427a-af31-29f4d898a689",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>745</th>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>746</th>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>747</th>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8477</th>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8478</th>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8479</th>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8480</th>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8486</th>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>723 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age\n",
       "745   44.0\n",
       "746   70.0\n",
       "747   24.0\n",
       "748   27.0\n",
       "749   32.0\n",
       "...    ...\n",
       "8477  48.0\n",
       "8478  51.0\n",
       "8479  40.0\n",
       "8480  36.0\n",
       "8486  30.0\n",
       "\n",
       "[723 rows x 1 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "age = pd.DataFrame(bogota[\"age\"], columns = [\"age\"])\n",
    "age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b39574da-9554-4139-91ca-49017803e595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_educ_3.0</th>\n",
       "      <th>level_educ_4.0</th>\n",
       "      <th>level_educ_5.0</th>\n",
       "      <th>level_educ_6.0</th>\n",
       "      <th>marital_status_2.0</th>\n",
       "      <th>marital_status_3.0</th>\n",
       "      <th>marital_status_4.0</th>\n",
       "      <th>marital_status_5.0</th>\n",
       "      <th>gender_2.0</th>\n",
       "      <th>own_status_1</th>\n",
       "      <th>Sanserv2_2.0</th>\n",
       "      <th>Watserv_10.0</th>\n",
       "      <th>Kitchen_2.0</th>\n",
       "      <th>Kitchen_3.0</th>\n",
       "      <th>Kitchen_6.0</th>\n",
       "      <th>Fuelc_3.0</th>\n",
       "      <th>Fuelc_4.0</th>\n",
       "      <th>Fuelc_5.0</th>\n",
       "      <th>Phone_service_2.0</th>\n",
       "      <th>tvservice_2.0</th>\n",
       "      <th>Internet_service_2.0</th>\n",
       "      <th>Washing_2.0</th>\n",
       "      <th>Refrigerator_2.0</th>\n",
       "      <th>Blender_2.0</th>\n",
       "      <th>Stove_2.0</th>\n",
       "      <th>Oven_2.0</th>\n",
       "      <th>Microwave_2.0</th>\n",
       "      <th>Water_heater_2.0</th>\n",
       "      <th>ColorTV_2.0</th>\n",
       "      <th>Computer_2.0</th>\n",
       "      <th>AirCond_2.0</th>\n",
       "      <th>typeofbuilding_2.0</th>\n",
       "      <th>Stereo_2.0</th>\n",
       "      <th>Floor_3.0</th>\n",
       "      <th>Floor_4.0</th>\n",
       "      <th>Floor_5.0</th>\n",
       "      <th>Floor_6.0</th>\n",
       "      <th>Garbcollectfreq_3.0</th>\n",
       "      <th>Garbcollectfreq_4.0</th>\n",
       "      <th>Utilrank_2.0</th>\n",
       "      <th>Utilrank_3.0</th>\n",
       "      <th>Utilrank_4.0</th>\n",
       "      <th>Utilrank_5.0</th>\n",
       "      <th>Utilrank_6.0</th>\n",
       "      <th>Naturalgas_2.0</th>\n",
       "      <th>Frequencewat_2.0</th>\n",
       "      <th>Numrooms</th>\n",
       "      <th>Numroomsleep</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.2</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>723 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_educ_3.0  level_educ_4.0  level_educ_5.0  level_educ_6.0  \\\n",
       "0               0.0             0.0             0.0             1.0   \n",
       "1               1.0             0.0             0.0             0.0   \n",
       "2               0.0             0.0             1.0             0.0   \n",
       "3               0.0             0.0             0.0             1.0   \n",
       "4               0.0             0.0             1.0             0.0   \n",
       "..              ...             ...             ...             ...   \n",
       "718             0.0             0.0             1.0             0.0   \n",
       "719             0.0             1.0             0.0             0.0   \n",
       "720             0.0             0.0             1.0             0.0   \n",
       "721             0.0             0.0             1.0             0.0   \n",
       "722             0.0             0.0             0.0             1.0   \n",
       "\n",
       "     marital_status_2.0  marital_status_3.0  marital_status_4.0  \\\n",
       "0                   0.0                 1.0                 0.0   \n",
       "1                   0.0                 0.0                 0.0   \n",
       "2                   1.0                 0.0                 0.0   \n",
       "3                   0.0                 0.0                 0.0   \n",
       "4                   1.0                 0.0                 0.0   \n",
       "..                  ...                 ...                 ...   \n",
       "718                 0.0                 0.0                 0.0   \n",
       "719                 0.0                 0.0                 1.0   \n",
       "720                 1.0                 0.0                 0.0   \n",
       "721                 1.0                 0.0                 0.0   \n",
       "722                 1.0                 0.0                 0.0   \n",
       "\n",
       "     marital_status_5.0  gender_2.0  own_status_1  Sanserv2_2.0  Watserv_10.0  \\\n",
       "0                   0.0         1.0           0.0           0.0           0.0   \n",
       "1                   0.0         1.0           0.0           0.0           0.0   \n",
       "2                   0.0         0.0           0.0           0.0           0.0   \n",
       "3                   0.0         0.0           1.0           0.0           0.0   \n",
       "4                   0.0         1.0           0.0           0.0           0.0   \n",
       "..                  ...         ...           ...           ...           ...   \n",
       "718                 0.0         1.0           0.0           0.0           0.0   \n",
       "719                 0.0         0.0           0.0           0.0           0.0   \n",
       "720                 0.0         0.0           0.0           0.0           0.0   \n",
       "721                 0.0         0.0           0.0           0.0           0.0   \n",
       "722                 0.0         0.0           0.0           0.0           0.0   \n",
       "\n",
       "     Kitchen_2.0  Kitchen_3.0  Kitchen_6.0  Fuelc_3.0  Fuelc_4.0  Fuelc_5.0  \\\n",
       "0            0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "1            0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "2            0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "3            0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "4            0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "..           ...          ...          ...        ...        ...        ...   \n",
       "718          0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "719          0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "720          0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "721          0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "722          0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "\n",
       "     Phone_service_2.0  tvservice_2.0  Internet_service_2.0  Washing_2.0  \\\n",
       "0                  1.0            0.0                   0.0          0.0   \n",
       "1                  1.0            1.0                   1.0          0.0   \n",
       "2                  1.0            0.0                   0.0          1.0   \n",
       "3                  1.0            0.0                   0.0          0.0   \n",
       "4                  0.0            1.0                   0.0          1.0   \n",
       "..                 ...            ...                   ...          ...   \n",
       "718                1.0            0.0                   0.0          0.0   \n",
       "719                1.0            0.0                   0.0          0.0   \n",
       "720                1.0            0.0                   0.0          0.0   \n",
       "721                1.0            0.0                   0.0          0.0   \n",
       "722                0.0            0.0                   1.0          0.0   \n",
       "\n",
       "     Refrigerator_2.0  Blender_2.0  Stove_2.0  Oven_2.0  Microwave_2.0  \\\n",
       "0                 0.0          0.0        0.0       1.0            1.0   \n",
       "1                 0.0          0.0        0.0       1.0            1.0   \n",
       "2                 0.0          1.0        0.0       1.0            0.0   \n",
       "3                 0.0          0.0        0.0       0.0            0.0   \n",
       "4                 0.0          0.0        0.0       1.0            1.0   \n",
       "..                ...          ...        ...       ...            ...   \n",
       "718               0.0          0.0        0.0       1.0            1.0   \n",
       "719               0.0          0.0        0.0       1.0            1.0   \n",
       "720               0.0          0.0        0.0       0.0            1.0   \n",
       "721               0.0          0.0        0.0       1.0            0.0   \n",
       "722               0.0          0.0        0.0       1.0            1.0   \n",
       "\n",
       "     Water_heater_2.0  ColorTV_2.0  Computer_2.0  AirCond_2.0  \\\n",
       "0                 0.0          0.0           0.0          1.0   \n",
       "1                 1.0          0.0           1.0          1.0   \n",
       "2                 0.0          0.0           1.0          1.0   \n",
       "3                 0.0          0.0           0.0          1.0   \n",
       "4                 1.0          0.0           1.0          1.0   \n",
       "..                ...          ...           ...          ...   \n",
       "718               1.0          0.0           1.0          1.0   \n",
       "719               0.0          0.0           1.0          1.0   \n",
       "720               0.0          0.0           1.0          1.0   \n",
       "721               1.0          0.0           0.0          1.0   \n",
       "722               0.0          0.0           1.0          1.0   \n",
       "\n",
       "     typeofbuilding_2.0  Stereo_2.0  Floor_3.0  Floor_4.0  Floor_5.0  \\\n",
       "0                   1.0         0.0        0.0        1.0        0.0   \n",
       "1                   1.0         0.0        0.0        1.0        0.0   \n",
       "2                   1.0         1.0        0.0        1.0        0.0   \n",
       "3                   0.0         1.0        0.0        1.0        0.0   \n",
       "4                   1.0         0.0        0.0        0.0        0.0   \n",
       "..                  ...         ...        ...        ...        ...   \n",
       "718                 1.0         1.0        0.0        1.0        0.0   \n",
       "719                 1.0         1.0        0.0        1.0        0.0   \n",
       "720                 1.0         1.0        0.0        1.0        0.0   \n",
       "721                 1.0         0.0        0.0        1.0        0.0   \n",
       "722                 1.0         1.0        0.0        1.0        0.0   \n",
       "\n",
       "     Floor_6.0  Garbcollectfreq_3.0  Garbcollectfreq_4.0  Utilrank_2.0  \\\n",
       "0          0.0                  1.0                  0.0           0.0   \n",
       "1          0.0                  1.0                  0.0           0.0   \n",
       "2          0.0                  1.0                  0.0           0.0   \n",
       "3          0.0                  1.0                  0.0           0.0   \n",
       "4          0.0                  1.0                  0.0           0.0   \n",
       "..         ...                  ...                  ...           ...   \n",
       "718        0.0                  1.0                  0.0           1.0   \n",
       "719        0.0                  1.0                  0.0           0.0   \n",
       "720        0.0                  1.0                  0.0           1.0   \n",
       "721        0.0                  1.0                  0.0           1.0   \n",
       "722        0.0                  1.0                  0.0           0.0   \n",
       "\n",
       "     Utilrank_3.0  Utilrank_4.0  Utilrank_5.0  Utilrank_6.0  Naturalgas_2.0  \\\n",
       "0             1.0           0.0           0.0           0.0             0.0   \n",
       "1             0.0           0.0           0.0           0.0             0.0   \n",
       "2             0.0           0.0           0.0           0.0             0.0   \n",
       "3             1.0           0.0           0.0           0.0             0.0   \n",
       "4             0.0           0.0           0.0           0.0             0.0   \n",
       "..            ...           ...           ...           ...             ...   \n",
       "718           0.0           0.0           0.0           0.0             0.0   \n",
       "719           1.0           0.0           0.0           0.0             0.0   \n",
       "720           0.0           0.0           0.0           0.0             0.0   \n",
       "721           0.0           0.0           0.0           0.0             0.0   \n",
       "722           1.0           0.0           0.0           0.0             0.0   \n",
       "\n",
       "     Frequencewat_2.0  Numrooms  Numroomsleep   age  \n",
       "0                 1.0  0.428571           0.4  44.0  \n",
       "1                 1.0  0.142857           0.0  70.0  \n",
       "2                 1.0  0.000000           0.0  24.0  \n",
       "3                 1.0  0.428571           0.2  27.0  \n",
       "4                 1.0  0.142857           0.0  32.0  \n",
       "..                ...       ...           ...   ...  \n",
       "718               1.0  0.285714           0.2  48.0  \n",
       "719               1.0  0.000000           0.0  51.0  \n",
       "720               1.0  0.428571           0.4  40.0  \n",
       "721               1.0  0.285714           0.2  36.0  \n",
       "722               1.0  0.285714           0.2  30.0  \n",
       "\n",
       "[723 rows x 49 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.reset_index(drop=True, inplace=True)\n",
    "data_preprocess.reset_index(drop=True, inplace=True)\n",
    "age.reset_index(drop=True, inplace=True)\n",
    "# on cree notre base pour la regression : on concatene les trois bases precedentes\n",
    "X = pd.concat([data, data_preprocess], axis=1)\n",
    "X = pd.concat([X, age], axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "90c1cd6c-5714-499d-8456-2313548735b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level_educ_3.0</th>\n",
       "      <th>level_educ_4.0</th>\n",
       "      <th>level_educ_5.0</th>\n",
       "      <th>level_educ_6.0</th>\n",
       "      <th>marital_status_2.0</th>\n",
       "      <th>marital_status_3.0</th>\n",
       "      <th>marital_status_4.0</th>\n",
       "      <th>marital_status_5.0</th>\n",
       "      <th>gender_2.0</th>\n",
       "      <th>own_status_1</th>\n",
       "      <th>Sanserv2_2.0</th>\n",
       "      <th>Watserv_10.0</th>\n",
       "      <th>Kitchen_2.0</th>\n",
       "      <th>Kitchen_3.0</th>\n",
       "      <th>Kitchen_6.0</th>\n",
       "      <th>Fuelc_3.0</th>\n",
       "      <th>Fuelc_4.0</th>\n",
       "      <th>Fuelc_5.0</th>\n",
       "      <th>Phone_service_2.0</th>\n",
       "      <th>tvservice_2.0</th>\n",
       "      <th>Internet_service_2.0</th>\n",
       "      <th>Washing_2.0</th>\n",
       "      <th>Refrigerator_2.0</th>\n",
       "      <th>Blender_2.0</th>\n",
       "      <th>Stove_2.0</th>\n",
       "      <th>Oven_2.0</th>\n",
       "      <th>Microwave_2.0</th>\n",
       "      <th>Water_heater_2.0</th>\n",
       "      <th>ColorTV_2.0</th>\n",
       "      <th>Computer_2.0</th>\n",
       "      <th>AirCond_2.0</th>\n",
       "      <th>typeofbuilding_2.0</th>\n",
       "      <th>Stereo_2.0</th>\n",
       "      <th>Floor_3.0</th>\n",
       "      <th>Floor_4.0</th>\n",
       "      <th>Floor_5.0</th>\n",
       "      <th>Floor_6.0</th>\n",
       "      <th>Garbcollectfreq_3.0</th>\n",
       "      <th>Garbcollectfreq_4.0</th>\n",
       "      <th>Utilrank_2.0</th>\n",
       "      <th>Utilrank_3.0</th>\n",
       "      <th>Utilrank_4.0</th>\n",
       "      <th>Utilrank_5.0</th>\n",
       "      <th>Utilrank_6.0</th>\n",
       "      <th>Naturalgas_2.0</th>\n",
       "      <th>Frequencewat_2.0</th>\n",
       "      <th>Numrooms</th>\n",
       "      <th>Numroomsleep</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.2</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>657 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     level_educ_3.0  level_educ_4.0  level_educ_5.0  level_educ_6.0  \\\n",
       "0               0.0             0.0             0.0             1.0   \n",
       "1               1.0             0.0             0.0             0.0   \n",
       "2               0.0             0.0             1.0             0.0   \n",
       "3               0.0             0.0             0.0             1.0   \n",
       "4               0.0             0.0             1.0             0.0   \n",
       "..              ...             ...             ...             ...   \n",
       "718             0.0             0.0             1.0             0.0   \n",
       "719             0.0             1.0             0.0             0.0   \n",
       "720             0.0             0.0             1.0             0.0   \n",
       "721             0.0             0.0             1.0             0.0   \n",
       "722             0.0             0.0             0.0             1.0   \n",
       "\n",
       "     marital_status_2.0  marital_status_3.0  marital_status_4.0  \\\n",
       "0                   0.0                 1.0                 0.0   \n",
       "1                   0.0                 0.0                 0.0   \n",
       "2                   1.0                 0.0                 0.0   \n",
       "3                   0.0                 0.0                 0.0   \n",
       "4                   1.0                 0.0                 0.0   \n",
       "..                  ...                 ...                 ...   \n",
       "718                 0.0                 0.0                 0.0   \n",
       "719                 0.0                 0.0                 1.0   \n",
       "720                 1.0                 0.0                 0.0   \n",
       "721                 1.0                 0.0                 0.0   \n",
       "722                 1.0                 0.0                 0.0   \n",
       "\n",
       "     marital_status_5.0  gender_2.0  own_status_1  Sanserv2_2.0  Watserv_10.0  \\\n",
       "0                   0.0         1.0           0.0           0.0           0.0   \n",
       "1                   0.0         1.0           0.0           0.0           0.0   \n",
       "2                   0.0         0.0           0.0           0.0           0.0   \n",
       "3                   0.0         0.0           1.0           0.0           0.0   \n",
       "4                   0.0         1.0           0.0           0.0           0.0   \n",
       "..                  ...         ...           ...           ...           ...   \n",
       "718                 0.0         1.0           0.0           0.0           0.0   \n",
       "719                 0.0         0.0           0.0           0.0           0.0   \n",
       "720                 0.0         0.0           0.0           0.0           0.0   \n",
       "721                 0.0         0.0           0.0           0.0           0.0   \n",
       "722                 0.0         0.0           0.0           0.0           0.0   \n",
       "\n",
       "     Kitchen_2.0  Kitchen_3.0  Kitchen_6.0  Fuelc_3.0  Fuelc_4.0  Fuelc_5.0  \\\n",
       "0            0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "1            0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "2            0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "3            0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "4            0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "..           ...          ...          ...        ...        ...        ...   \n",
       "718          0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "719          0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "720          0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "721          0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "722          0.0          0.0          0.0        1.0        0.0        0.0   \n",
       "\n",
       "     Phone_service_2.0  tvservice_2.0  Internet_service_2.0  Washing_2.0  \\\n",
       "0                  1.0            0.0                   0.0          0.0   \n",
       "1                  1.0            1.0                   1.0          0.0   \n",
       "2                  1.0            0.0                   0.0          1.0   \n",
       "3                  1.0            0.0                   0.0          0.0   \n",
       "4                  0.0            1.0                   0.0          1.0   \n",
       "..                 ...            ...                   ...          ...   \n",
       "718                1.0            0.0                   0.0          0.0   \n",
       "719                1.0            0.0                   0.0          0.0   \n",
       "720                1.0            0.0                   0.0          0.0   \n",
       "721                1.0            0.0                   0.0          0.0   \n",
       "722                0.0            0.0                   1.0          0.0   \n",
       "\n",
       "     Refrigerator_2.0  Blender_2.0  Stove_2.0  Oven_2.0  Microwave_2.0  \\\n",
       "0                 0.0          0.0        0.0       1.0            1.0   \n",
       "1                 0.0          0.0        0.0       1.0            1.0   \n",
       "2                 0.0          1.0        0.0       1.0            0.0   \n",
       "3                 0.0          0.0        0.0       0.0            0.0   \n",
       "4                 0.0          0.0        0.0       1.0            1.0   \n",
       "..                ...          ...        ...       ...            ...   \n",
       "718               0.0          0.0        0.0       1.0            1.0   \n",
       "719               0.0          0.0        0.0       1.0            1.0   \n",
       "720               0.0          0.0        0.0       0.0            1.0   \n",
       "721               0.0          0.0        0.0       1.0            0.0   \n",
       "722               0.0          0.0        0.0       1.0            1.0   \n",
       "\n",
       "     Water_heater_2.0  ColorTV_2.0  Computer_2.0  AirCond_2.0  \\\n",
       "0                 0.0          0.0           0.0          1.0   \n",
       "1                 1.0          0.0           1.0          1.0   \n",
       "2                 0.0          0.0           1.0          1.0   \n",
       "3                 0.0          0.0           0.0          1.0   \n",
       "4                 1.0          0.0           1.0          1.0   \n",
       "..                ...          ...           ...          ...   \n",
       "718               1.0          0.0           1.0          1.0   \n",
       "719               0.0          0.0           1.0          1.0   \n",
       "720               0.0          0.0           1.0          1.0   \n",
       "721               1.0          0.0           0.0          1.0   \n",
       "722               0.0          0.0           1.0          1.0   \n",
       "\n",
       "     typeofbuilding_2.0  Stereo_2.0  Floor_3.0  Floor_4.0  Floor_5.0  \\\n",
       "0                   1.0         0.0        0.0        1.0        0.0   \n",
       "1                   1.0         0.0        0.0        1.0        0.0   \n",
       "2                   1.0         1.0        0.0        1.0        0.0   \n",
       "3                   0.0         1.0        0.0        1.0        0.0   \n",
       "4                   1.0         0.0        0.0        0.0        0.0   \n",
       "..                  ...         ...        ...        ...        ...   \n",
       "718                 1.0         1.0        0.0        1.0        0.0   \n",
       "719                 1.0         1.0        0.0        1.0        0.0   \n",
       "720                 1.0         1.0        0.0        1.0        0.0   \n",
       "721                 1.0         0.0        0.0        1.0        0.0   \n",
       "722                 1.0         1.0        0.0        1.0        0.0   \n",
       "\n",
       "     Floor_6.0  Garbcollectfreq_3.0  Garbcollectfreq_4.0  Utilrank_2.0  \\\n",
       "0          0.0                  1.0                  0.0           0.0   \n",
       "1          0.0                  1.0                  0.0           0.0   \n",
       "2          0.0                  1.0                  0.0           0.0   \n",
       "3          0.0                  1.0                  0.0           0.0   \n",
       "4          0.0                  1.0                  0.0           0.0   \n",
       "..         ...                  ...                  ...           ...   \n",
       "718        0.0                  1.0                  0.0           1.0   \n",
       "719        0.0                  1.0                  0.0           0.0   \n",
       "720        0.0                  1.0                  0.0           1.0   \n",
       "721        0.0                  1.0                  0.0           1.0   \n",
       "722        0.0                  1.0                  0.0           0.0   \n",
       "\n",
       "     Utilrank_3.0  Utilrank_4.0  Utilrank_5.0  Utilrank_6.0  Naturalgas_2.0  \\\n",
       "0             1.0           0.0           0.0           0.0             0.0   \n",
       "1             0.0           0.0           0.0           0.0             0.0   \n",
       "2             0.0           0.0           0.0           0.0             0.0   \n",
       "3             1.0           0.0           0.0           0.0             0.0   \n",
       "4             0.0           0.0           0.0           0.0             0.0   \n",
       "..            ...           ...           ...           ...             ...   \n",
       "718           0.0           0.0           0.0           0.0             0.0   \n",
       "719           1.0           0.0           0.0           0.0             0.0   \n",
       "720           0.0           0.0           0.0           0.0             0.0   \n",
       "721           0.0           0.0           0.0           0.0             0.0   \n",
       "722           1.0           0.0           0.0           0.0             0.0   \n",
       "\n",
       "     Frequencewat_2.0  Numrooms  Numroomsleep   age  \n",
       "0                 1.0  0.428571           0.4  44.0  \n",
       "1                 1.0  0.142857           0.0  70.0  \n",
       "2                 1.0  0.000000           0.0  24.0  \n",
       "3                 1.0  0.428571           0.2  27.0  \n",
       "4                 1.0  0.142857           0.0  32.0  \n",
       "..                ...       ...           ...   ...  \n",
       "718               1.0  0.285714           0.2  48.0  \n",
       "719               1.0  0.000000           0.0  51.0  \n",
       "720               1.0  0.428571           0.4  40.0  \n",
       "721               1.0  0.285714           0.2  36.0  \n",
       "722               1.0  0.285714           0.2  30.0  \n",
       "\n",
       "[657 rows x 49 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# on cree la base de la variable dependente a predire\n",
    "y = bogota['log_imputed_rent_uc']\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# et fin du preprocessing, on droppe les NaN\n",
    "X_y = pd.concat([X,y],axis=1)\n",
    "X_y = X_y.dropna()\n",
    "\n",
    "y = X_y['log_imputed_rent_uc']\n",
    "X = X_y.drop('log_imputed_rent_uc', axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c47afc06-8ba2-491b-8608-08072b1d518f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.22720519661828575, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2199988393048784, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6656415452723081, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6173504587429122, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV(alphas=array([1.00000000e-15, 1.41499130e-15, 2.00220037e-15, 2.83309610e-15,\n",
       "       4.00880633e-15, 5.67242607e-15, 8.02643352e-15, 1.13573336e-14,\n",
       "       1.60705282e-14, 2.27396575e-14, 3.21764175e-14, 4.55293507e-14,\n",
       "       6.44236351e-14, 9.11588830e-14, 1.28989026e-13, 1.82518349e-13,\n",
       "       2.58261876e-13, 3.65438307e-13, 5.17092024e-13, 7.31680714e-13,\n",
       "       1.03532184e-12, 1.46497140e-1...\n",
       "       3.40928507e+11, 4.82410870e+11, 6.82607183e+11, 9.65883224e+11,\n",
       "       1.36671636e+12, 1.93389175e+12, 2.73644000e+12, 3.87203878e+12,\n",
       "       5.47890118e+12, 7.75259749e+12, 1.09698580e+13, 1.55222536e+13,\n",
       "       2.19638537e+13, 3.10786619e+13, 4.39760361e+13, 6.22257084e+13,\n",
       "       8.80488358e+13, 1.24588336e+14, 1.76291412e+14, 2.49450814e+14,\n",
       "       3.52970730e+14, 4.99450512e+14, 7.06718127e+14, 1.00000000e+15]),\n",
       "        cv=5, max_iter=10000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV(alphas=array([1.00000000e-15, 1.41499130e-15, 2.00220037e-15, 2.83309610e-15,\n",
       "       4.00880633e-15, 5.67242607e-15, 8.02643352e-15, 1.13573336e-14,\n",
       "       1.60705282e-14, 2.27396575e-14, 3.21764175e-14, 4.55293507e-14,\n",
       "       6.44236351e-14, 9.11588830e-14, 1.28989026e-13, 1.82518349e-13,\n",
       "       2.58261876e-13, 3.65438307e-13, 5.17092024e-13, 7.31680714e-13,\n",
       "       1.03532184e-12, 1.46497140e-1...\n",
       "       3.40928507e+11, 4.82410870e+11, 6.82607183e+11, 9.65883224e+11,\n",
       "       1.36671636e+12, 1.93389175e+12, 2.73644000e+12, 3.87203878e+12,\n",
       "       5.47890118e+12, 7.75259749e+12, 1.09698580e+13, 1.55222536e+13,\n",
       "       2.19638537e+13, 3.10786619e+13, 4.39760361e+13, 6.22257084e+13,\n",
       "       8.80488358e+13, 1.24588336e+14, 1.76291412e+14, 2.49450814e+14,\n",
       "       3.52970730e+14, 4.99450512e+14, 7.06718127e+14, 1.00000000e+15]),\n",
       "        cv=5, max_iter=10000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV(alphas=array([1.00000000e-15, 1.41499130e-15, 2.00220037e-15, 2.83309610e-15,\n",
       "       4.00880633e-15, 5.67242607e-15, 8.02643352e-15, 1.13573336e-14,\n",
       "       1.60705282e-14, 2.27396575e-14, 3.21764175e-14, 4.55293507e-14,\n",
       "       6.44236351e-14, 9.11588830e-14, 1.28989026e-13, 1.82518349e-13,\n",
       "       2.58261876e-13, 3.65438307e-13, 5.17092024e-13, 7.31680714e-13,\n",
       "       1.03532184e-12, 1.46497140e-1...\n",
       "       3.40928507e+11, 4.82410870e+11, 6.82607183e+11, 9.65883224e+11,\n",
       "       1.36671636e+12, 1.93389175e+12, 2.73644000e+12, 3.87203878e+12,\n",
       "       5.47890118e+12, 7.75259749e+12, 1.09698580e+13, 1.55222536e+13,\n",
       "       2.19638537e+13, 3.10786619e+13, 4.39760361e+13, 6.22257084e+13,\n",
       "       8.80488358e+13, 1.24588336e+14, 1.76291412e+14, 2.49450814e+14,\n",
       "       3.52970730e+14, 4.99450512e+14, 7.06718127e+14, 1.00000000e+15]),\n",
       "        cv=5, max_iter=10000)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "############# Premiere regression LASSO pour selectionner les variables d'amenites\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LassoCV\n",
    "import numpy as np\n",
    "\n",
    "# on cree nos donnees de training\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# cross-validation \n",
    "lasso_model = LassoCV(alphas=np.logspace(-15, 15, 200), cv=5, max_iter=10000)\n",
    "\n",
    "# et on fitte avec les donnees de training\n",
    "lasso_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "501e0794-7bf1-40a7-89fb-e6bf32ddb423",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "optimal_alpha = lasso_model.alpha_ #notre alpha optimal\n",
    "optimal_alpha_original_scale = 10**optimal_alpha\n",
    "\n",
    "# avec ce alpha optimal, on reconduit une reg lasso, pour enfin selectionner les variables avec ce alpha optimal (donc minimisation du squared error)\n",
    "lasso_final = Lasso(alpha=optimal_alpha)\n",
    "\n",
    "# et on fitte le modele sur les donnes d'entrainement\n",
    "lasso_final.fit(X_train, y_train)\n",
    "\n",
    "# on extirpe les variables selectionnees \n",
    "pd.set_option('display.max_columns', None) #on veut voir toutes les colonnes de la base\n",
    "coefficients_df = pd.DataFrame({'Variable': X.columns, 'Coefficient': lasso_final.coef_})\n",
    "\n",
    "to_exclude = coefficients_df[coefficients_df['Coefficient'].abs()==0]\n",
    "to_exclude = [element.split('_')[0] for element in to_exclude['Variable']]\n",
    "to_exclude = list(set(to_exclude))\n",
    "\n",
    "others = coefficients_df[coefficients_df['Coefficient'].abs()!=0]\n",
    "others = [element.split('_')[0] for element in others['Variable']]\n",
    "others = list(set(others))\n",
    "features = list(set(others)-set(to_exclude))\n",
    " \n",
    "\n",
    "# renomme les vars avec des underscores \n",
    "\n",
    "# petit dictionnaire\n",
    "replacement_dict = {'Internet': 'Internet_service', 'Phone': 'Phone_service', 'Water': 'Water_heater', 'Sewage': 'Sewage_system',\n",
    "'own':'own_status', 'level':'level_educ', 'marital':'marital_status'}\n",
    "\n",
    "# on renomme\n",
    "features = [replacement_dict.get(col, col) for col in features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4cfcdd8-d7ee-4c40-b05c-f7e5703facb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0018714123142827"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimal_alpha_original_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9a116542-3115-4411-b958-2518a44126ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17387045588531655"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "y_pred = lasso_model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "mse #MSE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "143e55f1-6125-4250-be66-b66e74f017c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6142773730623005"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_score = lasso_model.score(X_test, y_test)\n",
    "test_score #R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aa78433d-2a91-4599-84bf-f040eb667863",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Naturalgas',\n",
       " 'Oven',\n",
       " 'Refrigerator',\n",
       " 'Blender',\n",
       " 'age',\n",
       " 'own_status',\n",
       " 'Stereo',\n",
       " 'Water_heater',\n",
       " 'Numrooms',\n",
       " 'Washing',\n",
       " 'Microwave',\n",
       " 'tvservice',\n",
       " 'Sanserv2',\n",
       " 'ColorTV',\n",
       " 'Numroomsleep',\n",
       " 'Phone_service',\n",
       " 'Internet_service',\n",
       " 'Utilrank',\n",
       " 'Watserv',\n",
       " 'typeofbuilding',\n",
       " 'AirCond']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features\n",
    "# les caracteristiques marital_status et level_educ ont ete supprimes \n",
    "# on les reintegre dans le deuxieme LASSO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "d8c81774-002e-46a7-9cc8-2d6a03109fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# VIF \n",
    "import pandas as pd\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "data_for_vif = bogota[features].copy()\n",
    "\n",
    "#drop na\n",
    "data_for_vif.dropna(inplace=True)\n",
    "\n",
    "# VIF pour chaque var\n",
    "vif_data = pd.DataFrame()\n",
    "vif_data[\"Variable\"] = data_for_vif.columns\n",
    "vif_data[\"VIF\"] = [variance_inflation_factor(data_for_vif.values, i) for i in range(data_for_vif.shape[1])]\n",
    "\n",
    "high_vif_variables = vif_data[vif_data[\"VIF\"]>50][\"Variable\"].tolist()\n",
    "\n",
    "#on supprime les VIF\n",
    "features_after_removal = [var for var in features if var not in high_vif_variables]\n",
    "\n",
    "data_after_removal = bogota[features_after_removal].copy()\n",
    "\n",
    "data_after_removal.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d68f965e-aaeb-4bbe-ad4a-106a13e36cac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naturalgas</th>\n",
       "      <th>Oven</th>\n",
       "      <th>Refrigerator</th>\n",
       "      <th>Blender</th>\n",
       "      <th>age</th>\n",
       "      <th>own_status</th>\n",
       "      <th>Stereo</th>\n",
       "      <th>Water_heater</th>\n",
       "      <th>Washing</th>\n",
       "      <th>Microwave</th>\n",
       "      <th>tvservice</th>\n",
       "      <th>Sanserv2</th>\n",
       "      <th>ColorTV</th>\n",
       "      <th>Phone_service</th>\n",
       "      <th>Internet_service</th>\n",
       "      <th>Utilrank</th>\n",
       "      <th>Watserv</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>level_educ</th>\n",
       "      <th>gender</th>\n",
       "      <th>log_imputed_rent_uc</th>\n",
       "      <th>Numrooms</th>\n",
       "      <th>Numroomsleep</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.899220</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.670429</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.871100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.671670</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.216382</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.909529</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.899220</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.562956</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.884489</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.429216</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>657 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Naturalgas  Oven  Refrigerator  Blender   age  own_status  Stereo  \\\n",
       "0           1.0   2.0           1.0      1.0  44.0           0     1.0   \n",
       "1           1.0   2.0           1.0      1.0  70.0           0     1.0   \n",
       "2           1.0   2.0           1.0      2.0  24.0           0     2.0   \n",
       "3           1.0   1.0           1.0      1.0  27.0           1     2.0   \n",
       "4           1.0   2.0           1.0      1.0  32.0           0     1.0   \n",
       "..          ...   ...           ...      ...   ...         ...     ...   \n",
       "718         1.0   2.0           1.0      1.0  48.0           0     2.0   \n",
       "719         1.0   2.0           1.0      1.0  51.0           0     2.0   \n",
       "720         1.0   1.0           1.0      1.0  40.0           0     2.0   \n",
       "721         1.0   2.0           1.0      1.0  36.0           0     1.0   \n",
       "722         1.0   2.0           1.0      1.0  30.0           0     2.0   \n",
       "\n",
       "     Water_heater  Washing  Microwave  tvservice  Sanserv2  ColorTV  \\\n",
       "0             1.0      1.0        2.0        1.0       1.0      1.0   \n",
       "1             2.0      1.0        2.0        2.0       1.0      1.0   \n",
       "2             1.0      2.0        1.0        1.0       1.0      1.0   \n",
       "3             1.0      1.0        1.0        1.0       1.0      1.0   \n",
       "4             2.0      2.0        2.0        2.0       1.0      1.0   \n",
       "..            ...      ...        ...        ...       ...      ...   \n",
       "718           2.0      1.0        2.0        1.0       1.0      1.0   \n",
       "719           1.0      1.0        2.0        1.0       1.0      1.0   \n",
       "720           1.0      1.0        2.0        1.0       1.0      1.0   \n",
       "721           2.0      1.0        1.0        1.0       1.0      1.0   \n",
       "722           1.0      1.0        2.0        1.0       1.0      1.0   \n",
       "\n",
       "     Phone_service  Internet_service  Utilrank  Watserv  marital_status  \\\n",
       "0              2.0               1.0       3.0      1.0             3.0   \n",
       "1              2.0               2.0       1.0      1.0             1.0   \n",
       "2              2.0               1.0       1.0      1.0             2.0   \n",
       "3              2.0               1.0       3.0      1.0             1.0   \n",
       "4              1.0               1.0       1.0      1.0             2.0   \n",
       "..             ...               ...       ...      ...             ...   \n",
       "718            2.0               1.0       2.0      1.0             1.0   \n",
       "719            2.0               1.0       3.0      1.0             4.0   \n",
       "720            2.0               1.0       2.0      1.0             2.0   \n",
       "721            2.0               1.0       2.0      1.0             2.0   \n",
       "722            1.0               2.0       3.0      1.0             2.0   \n",
       "\n",
       "     level_educ  gender  log_imputed_rent_uc  Numrooms  Numroomsleep  \n",
       "0           6.0     2.0            12.899220  0.428571           0.4  \n",
       "1           3.0     2.0            12.670429  0.142857           0.0  \n",
       "2           5.0     1.0            12.871100  0.000000           0.0  \n",
       "3           6.0     1.0            13.671670  0.428571           0.2  \n",
       "4           5.0     2.0            12.216382  0.142857           0.0  \n",
       "..          ...     ...                  ...       ...           ...  \n",
       "718         5.0     2.0            12.909529  0.285714           0.2  \n",
       "719         4.0     1.0            12.899220  0.000000           0.0  \n",
       "720         5.0     1.0            12.562956  0.428571           0.4  \n",
       "721         5.0     1.0            11.884489  0.285714           0.2  \n",
       "722         6.0     1.0            12.429216  0.285714           0.2  \n",
       "\n",
       "[657 rows x 23 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_after_removal = data_after_removal.drop([\"Numroomsleep\", \"Numrooms\"], axis=1)\n",
    "dummies = pd.get_dummies(data_after_removal, prefix=column, dtype=float, drop_first=True)\n",
    "\n",
    "soc = pd.DataFrame(bogota[['marital_status','level_educ','gender','log_imputed_rent_uc','Numrooms','Numroomsleep']], columns = ['marital_status','level_educ','gender','log_imputed_rent_uc','Numrooms','Numroomsleep'])\n",
    "scaler = MinMaxScaler()\n",
    "rooms = scaler.fit_transform(soc[['Numrooms', 'Numroomsleep']])\n",
    "soc = soc.drop([\"Numroomsleep\", \"Numrooms\"], axis=1)\n",
    "rooms = pd.DataFrame(rooms, columns=['Numrooms',\"Numroomsleep\"])\n",
    "\n",
    "soc.reset_index(drop=True, inplace=True)\n",
    "dummies.reset_index(drop=True, inplace=True)\n",
    "rooms.reset_index(drop=True, inplace=True)\n",
    "\n",
    "clean  = pd.concat([dummies,soc],axis=1)\n",
    "clean = pd.concat([clean,rooms],axis=1)\n",
    "clean = clean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "11d104be-f793-4622-b7b0-39f0d8e3a815",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = clean.drop(['log_imputed_rent_uc'], axis=1)\n",
    "y = clean['log_imputed_rent_uc'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "afbd28f3-0918-4f0f-bcf8-51d0fcd4334c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.16127542870350453, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.415916777645549, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.406628283852577, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.304228043741382, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.737261960381872, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.749675239001405, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.03439400544581, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.446009794432417, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.5864666340656, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.07421060625547, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.15116869918692, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.09907297156788, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.49144749749075, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.15451001830313, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.1351887535774, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.10975951692731, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.31262407494605, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.15192937898328, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.92077340848278, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.602413535109335, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.70706016394423, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.77136401680741, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.81954376622517, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.533331446124926, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.64115662138337, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.92880039913092, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.24227009514839, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.936219731933136, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.92950096796984, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.887371535166444, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.9064419373668, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.94201710858544, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.94736632426908, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.95535268278611, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96075926931016, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.961082204145335, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.95829998821571, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.95580480636435, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96190854648868, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96247222663539, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.960161274738525, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96284218176333, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.962430389968524, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.962652445394724, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96232304066734, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.962572060925616, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.9630364688373, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96310628423664, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.963158562766054, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96325605881516, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.962964867850694, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.963270784868186, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.963265409798545, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96328994784323, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96325945973199, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.963273262207295, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96329900290914, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96329133692965, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331095297728, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331009602837, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.9633111791949, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96330715449322, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96329268164705, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331034091248, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331364677314, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331212759185, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331398124419, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331376879436, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331392940021, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.963313691151775, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331427394667, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331400612799, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331425764671, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331437999598, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.963314239367435, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331428177023, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331436084856, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.96331437273661, tolerance: 0.020630153559399744\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2334242039304968, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8019980331649492, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.512780310377345, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30.739711446323724, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.012468874177493, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 22.090014417527755, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.27976114030123, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.279348576012765, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.2589491536312, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.54602273555068, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.73246453801889, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.789034089206162, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.762544786643794, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.61161689473219, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.957589250939726, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.68434299661825, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.42773480529586, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.24307600000505, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.34198143935742, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.04932761795453, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.874120701070886, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.85900592764783, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.790472964146524, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.94531824343091, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.938966766245834, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.30539971105141, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.306492360755854, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.97256074156799, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.98473993757768, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.96960773219353, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.97645802549167, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.981587930430585, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.991155625733704, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.994023391915945, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99527664441925, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.919970964266035, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.993281234529974, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99418573737279, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99486304431887, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.98478732384921, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99575000385039, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99603438942614, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996247340874476, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.9967633231777, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.9965262073721, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99661561986562, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99668257292621, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996852272849246, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99682620694568, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99654695442445, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99681941185253, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996866500887435, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996873367499724, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99687338145242, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996878218155004, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99687477722387, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99687995152374, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99687388021099, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996875961027655, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99687984161209, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99688042498676, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99688086182378, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996874363038714, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996880703688184, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996881981802645, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996881345204464, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99688204142606, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996882011010904, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99688209529685, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996882035334046, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99688209979888, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99688212797025, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996882110011505, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996882123587824, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.996882133753836, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99688211867311, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.99688213007373, tolerance: 0.02166797495240206\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.7450150959691086, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.39790679040356, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 11.674182348120922, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.44654557792097194, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.50893640326926, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.4447154701512943, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21.40598761416095, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26.43503159614107, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.230058414002265, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.012313466756595, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.37416725355991, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.362322618798686, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 14.331085283844814, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.78449604505495, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.675375180337454, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.565458151287956, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.81735161177455, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.44394426635826, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.14831103052849, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.413486960810566, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.41373906382863, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.501173776117895, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.30555577802049, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.50584638472889, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.42275131648501, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.46036022120155, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.48853257914672, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.556831059670046, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.52543854637989, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.53727486011105, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.54613904472505, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.56597119162115, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.56515828347079, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.513395110472004, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.56841357080325, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.54767930590615, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.535296311064535, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.571871016103366, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.571262437159504, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57061231524125, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57110378800503, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.568180583558856, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.571747389143184, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.56764770603837, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57233859037347, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57222397773474, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.571535754407286, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57237550136217, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.5719896015366, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57254179987717, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57252830828989, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57208244076857, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.572523377612214, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57243252543943, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.572556146095664, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57254979348222, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57255459587251, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57256355201121, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.572560884734564, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57256290111784, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.572564411006596, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57256554162695, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.572558816779136, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57256828211525, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.572568440353386, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.572567852390854, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.572565738074715, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57256415862875, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57256876376071, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57256857890325, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.572568787330695, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57256872525781, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.572568865441156, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57256887715388, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57256883363311, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57256885333567, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.572568890079665, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57256887913674, tolerance: 0.020815224341918112\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 8.8201423454626, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.8413407858890878, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1421413088563952, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3.637582507965263, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.305980428345798, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.6228054112376924, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.173644989842444, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.852912214040348, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.04366699977943, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.102946870341874, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.97094742458451, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.00881414926389, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.184003009589652, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.3383343026325, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.81958738697856, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.07386575814779, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.76613278004128, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.696199868175256, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.09567492940786, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.15586694263878, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.06658892956295, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.13407316683978, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.23490444309826, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.109638519472625, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.43647210696831, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 48.32721645187824, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 49.95644768340427, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.264445377922826, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.308901643759455, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.315586526428355, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.32059252678103, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.324341234882965, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.32714839786604, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.322984180594254, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.32613219145813, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.27930967701642, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33376300060635, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33354686130871, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.332566407467255, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33441238116739, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.32889911556931, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.335104188112965, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33458943278551, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.320697891143006, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.334996972408085, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33532240711743, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.335419944664, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33529875589969, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.3353536200567, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33547634987637, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33542546621776, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.3354828377299, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.335465751603586, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33549792079432, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33550996510893, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33549558287676, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33543094839017, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33542032413373, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33548091250583, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.335490020858565, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.335512090353625, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.335515270265944, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33550577282837, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33551610626982, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.335516773845846, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.335515976686914, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33551672532935, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33551683787402, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33550913410126, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33551115348356, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33551703250845, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.3355170678929, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33551701540241, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33551705508368, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33551712908668, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33551714021172, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33551712370848, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 50.33551702460993, tolerance: 0.02094332139144695\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.27860173343681, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21.72112197891959, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20.030334383684202, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 13.220649370871591, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.238557558266237, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.748583642061696, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31.72115090042334, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34.783800724042266, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.572760772579414, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.192571587065302, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.97768389072846, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20.831725482456886, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.83345457014676, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.270821717071115, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.333726610841325, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.9910347406754, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.615714179796164, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.86874135496573, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.5719358344279, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.3717250087882, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.86335777638145, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.80677373004117, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.84954571524991, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.881589654812046, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.9055933672871, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.92357257437947, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.81669628419494, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.96215760286837, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.965934535375126, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.9603317668178, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97088081601174, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97246679864335, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97011410751285, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97586930599679, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.9752096721439, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.976451613504, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.96829010217067, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97552781825065, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97594656810935, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97345590832264, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.976844916556765, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97667075876344, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97510168597833, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.976019327038166, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.9771215414975, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97703010686874, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97713319975333, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97717179830074, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97712570740523, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97714308753894, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.977156101966266, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97718037301167, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.977184021718514, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.977178609097166, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97709731606163, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97718576485134, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97719147895209, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.977192337962336, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97716421837265, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.977148951199105, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.977192748345765, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97716913516078, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97718525270864, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97718767568642, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97719422263476, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97719464559026, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97718883323956, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.977194804097344, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.977194686156494, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97719473955026, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.977194779532084, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.9771948094709, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97719436407406, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.9771946985459, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97719487998356, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "/opt/mamba/lib/python3.10/site-packages/sklearn/linear_model/_coordinate_descent.py:614: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.97719478647898, tolerance: 0.018846397531120426\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LassoCV(alphas=array([1.00000000e-25, 1.33545156e-25, 1.78343088e-25, 2.38168555e-25,\n",
       "       3.18062569e-25, 4.24757155e-25, 5.67242607e-25, 7.57525026e-25,\n",
       "       1.01163798e-24, 1.35099352e-24, 1.80418641e-24, 2.40940356e-24,\n",
       "       3.21764175e-24, 4.29700470e-24, 5.73844165e-24, 7.66341087e-24,\n",
       "       1.02341140e-23, 1.36671636e-23, 1.82518349e-23, 2.43744415e-23,\n",
       "       3.25508860e-23, 4.34701316e-2...\n",
       "       1.28989026e-03, 1.72258597e-03, 2.30043012e-03, 3.07211300e-03,\n",
       "       4.10265811e-03, 5.47890118e-03, 7.31680714e-03, 9.77124154e-03,\n",
       "       1.30490198e-02, 1.74263339e-02, 2.32720248e-02, 3.10786619e-02,\n",
       "       4.15040476e-02, 5.54266452e-02, 7.40196000e-02, 9.88495905e-02,\n",
       "       1.32008840e-01, 1.76291412e-01, 2.35428641e-01, 3.14403547e-01,\n",
       "       4.19870708e-01, 5.60716994e-01, 7.48810386e-01, 1.00000000e+00]),\n",
       "        cv=5, max_iter=100)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LassoCV</label><div class=\"sk-toggleable__content\"><pre>LassoCV(alphas=array([1.00000000e-25, 1.33545156e-25, 1.78343088e-25, 2.38168555e-25,\n",
       "       3.18062569e-25, 4.24757155e-25, 5.67242607e-25, 7.57525026e-25,\n",
       "       1.01163798e-24, 1.35099352e-24, 1.80418641e-24, 2.40940356e-24,\n",
       "       3.21764175e-24, 4.29700470e-24, 5.73844165e-24, 7.66341087e-24,\n",
       "       1.02341140e-23, 1.36671636e-23, 1.82518349e-23, 2.43744415e-23,\n",
       "       3.25508860e-23, 4.34701316e-2...\n",
       "       1.28989026e-03, 1.72258597e-03, 2.30043012e-03, 3.07211300e-03,\n",
       "       4.10265811e-03, 5.47890118e-03, 7.31680714e-03, 9.77124154e-03,\n",
       "       1.30490198e-02, 1.74263339e-02, 2.32720248e-02, 3.10786619e-02,\n",
       "       4.15040476e-02, 5.54266452e-02, 7.40196000e-02, 9.88495905e-02,\n",
       "       1.32008840e-01, 1.76291412e-01, 2.35428641e-01, 3.14403547e-01,\n",
       "       4.19870708e-01, 5.60716994e-01, 7.48810386e-01, 1.00000000e+00]),\n",
       "        cv=5, max_iter=100)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LassoCV(alphas=array([1.00000000e-25, 1.33545156e-25, 1.78343088e-25, 2.38168555e-25,\n",
       "       3.18062569e-25, 4.24757155e-25, 5.67242607e-25, 7.57525026e-25,\n",
       "       1.01163798e-24, 1.35099352e-24, 1.80418641e-24, 2.40940356e-24,\n",
       "       3.21764175e-24, 4.29700470e-24, 5.73844165e-24, 7.66341087e-24,\n",
       "       1.02341140e-23, 1.36671636e-23, 1.82518349e-23, 2.43744415e-23,\n",
       "       3.25508860e-23, 4.34701316e-2...\n",
       "       1.28989026e-03, 1.72258597e-03, 2.30043012e-03, 3.07211300e-03,\n",
       "       4.10265811e-03, 5.47890118e-03, 7.31680714e-03, 9.77124154e-03,\n",
       "       1.30490198e-02, 1.74263339e-02, 2.32720248e-02, 3.10786619e-02,\n",
       "       4.15040476e-02, 5.54266452e-02, 7.40196000e-02, 9.88495905e-02,\n",
       "       1.32008840e-01, 1.76291412e-01, 2.35428641e-01, 3.14403547e-01,\n",
       "       4.19870708e-01, 5.60716994e-01, 7.48810386e-01, 1.00000000e+00]),\n",
       "        cv=5, max_iter=100)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "############ deuxieme LASSO/ nested LASSO \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "#cross validation pour determiner le alpha optimal \n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# LassoCV model avec cross-validation\n",
    "lasso_model2 = LassoCV(alphas=np.logspace(-25, 0, 200), cv=5, max_iter=100)\n",
    "\n",
    "# on fitte les donnees avec les data_train2\n",
    "lasso_model2.fit(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dda2344a-0b00-4149-8752-d017c2cda19a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot alpha optimal \n",
    "m_log_alphas = -np.log10(lasso_model2.alphas_)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(m_log_alphas, lasso_model2.mse_path_, ':')\n",
    "plt.plot(m_log_alphas, lasso_model2.mse_path_.mean(axis=-1), 'k', label='Average across the folds', linewidth=2)\n",
    "plt.axvline(-np.log10(lasso_model2.alpha_), linestyle='--', color='k', label='Optimal Alpha')\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('-log10(alpha)')\n",
    "plt.ylabel('Mean Squared Error (MSE)')\n",
    "plt.title('LassoCV Mean Squared Error (MSE) Path')\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8aa78493-dc22-442f-9708-28047affbfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: 0.5393612594797318\n"
     ]
    }
   ],
   "source": [
    "test_score = lasso_model2.score(X_test2, y_test2)\n",
    "print(f'R-squared: {test_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "d2ac043b-fd59-443a-a40a-3e1d9560c567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alpha optimal: 1.0016667630072231\n"
     ]
    }
   ],
   "source": [
    "optimal_alpha2 = lasso_model2.alpha_\n",
    "optimal_alpha_original_scale2 = 10**optimal_alpha2\n",
    "print(f'Alpha optimal: {optimal_alpha_original_scale2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d800395b-9699-4f39-9edb-a4f99867b102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.20764005588304038\n"
     ]
    }
   ],
   "source": [
    "lasso_model2_selec = Lasso(alpha=optimal_alpha2)  # utilise le alpha optimal\n",
    "lasso_model2_selec.fit(X_train2, y_train2)\n",
    "\n",
    "#on applique aux datas test et on calcule le MSE\n",
    "y_pred2 = lasso_model2_selec.predict(X_test2)\n",
    "mse = mean_squared_error(y_test2, y_pred2)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "9b15ed90-182a-47dd-98a4-6739919f14fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Naturalgas',\n",
       " 'Oven',\n",
       " 'Refrigerator',\n",
       " 'Blender',\n",
       " 'age',\n",
       " 'own',\n",
       " 'Stereo',\n",
       " 'level',\n",
       " 'Water',\n",
       " 'Washing',\n",
       " 'tvservice',\n",
       " 'Sanserv2',\n",
       " 'Microwave',\n",
       " 'Numrooms',\n",
       " 'ColorTV',\n",
       " 'marital',\n",
       " 'Numroomsleep',\n",
       " 'Phone',\n",
       " 'gender',\n",
       " 'Internet',\n",
       " 'Utilrank',\n",
       " 'Watserv']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coefficients_df2 = pd.DataFrame({'Variable': X.columns, 'Coefficient': lasso_model2_selec.coef_})\n",
    "coefficients_df2\n",
    "tokeep = [element.split('_')[0] for element in coefficients_df2['Variable']]\n",
    "tokeep = list(set(tokeep))\n",
    "tokeep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c6e23514-42fd-4b86-9c38-1a54870dccf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_exclude = coefficients_df2[coefficients_df2['Coefficient'].abs()==0]\n",
    "to_exclude = [element.split('_')[0] for element in to_exclude['Variable']]\n",
    "to_exclude = list(set(to_exclude))\n",
    "to_exclude # rien n'a ete exclus. on garde cette liste donc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e07f9932-a4dd-4c78-b33c-be2099d1ddfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les covariables retenues :['Naturalgas', 'Oven', 'Refrigerator', 'Blender', 'age', 'own_status', 'Stereo', 'level_educ', 'Water_heater', 'Washing', 'tvservice', 'Sanserv2', 'Microwave', 'Numrooms', 'ColorTV', 'marital_status', 'Numroomsleep', 'Phone_service', 'gender', 'Internet_service', 'Utilrank', 'Watserv']\n"
     ]
    }
   ],
   "source": [
    "#renommer \n",
    "tokeep = [replacement_dict.get(col, col) for col in tokeep]\n",
    "\n",
    "print(f'Les covariables retenues :{tokeep}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "96717f0a-e4f1-4dd4-9f5c-f0fbdd58357f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rooms = scaler.fit_transform(bogota[['Numrooms', 'Numroomsleep']])\n",
    "rooms = pd.DataFrame(rooms, columns=['Numrooms', 'Numroomsleep'])\n",
    "rooms.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "30bbedb6-bc91-4794-b952-fa7faa9313e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = bogota[['log_imputed_rent_uc', 'fex_c_2011']]\n",
    "X = bogota[tokeep]\n",
    "\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "X = X.drop(['Numrooms', 'Numroomsleep'],axis=1)\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "\n",
    "data_bogota_reg = pd.concat([X, rooms], axis=1)\n",
    "data_bogota_reg = pd.concat([data_bogota_reg, y], axis=1).dropna()\n",
    "data_bogota_reg['Utilrank'] = data_bogota_reg['Utilrank'].astype(int)\n",
    "\n",
    "#### regressions avec bogota tout seul \n",
    "##### on regresse en utilisant les poids fex_c_2011, car notre echantillon est reduit\n",
    "\n",
    "#creer des poids \n",
    "total_fex_c_2011 = data_bogota_reg['fex_c_2011'].sum()\n",
    "data_bogota_reg['fex_c_2011_ratio'] = data_bogota_reg['fex_c_2011'] / total_fex_c_2011\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "0de4cd42-2d96-48d3-bd57-64f204c6ade0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Naturalgas</th>\n",
       "      <th>Oven</th>\n",
       "      <th>Refrigerator</th>\n",
       "      <th>Blender</th>\n",
       "      <th>age</th>\n",
       "      <th>own_status</th>\n",
       "      <th>Stereo</th>\n",
       "      <th>level_educ</th>\n",
       "      <th>Water_heater</th>\n",
       "      <th>Washing</th>\n",
       "      <th>tvservice</th>\n",
       "      <th>Sanserv2</th>\n",
       "      <th>Microwave</th>\n",
       "      <th>ColorTV</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>Phone_service</th>\n",
       "      <th>gender</th>\n",
       "      <th>Internet_service</th>\n",
       "      <th>Utilrank</th>\n",
       "      <th>Watserv</th>\n",
       "      <th>Numrooms</th>\n",
       "      <th>Numroomsleep</th>\n",
       "      <th>log_imputed_rent_uc</th>\n",
       "      <th>fex_c_2011</th>\n",
       "      <th>fex_c_2011_ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "      <td>12.899220</td>\n",
       "      <td>2746.535202</td>\n",
       "      <td>0.001062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.670429</td>\n",
       "      <td>3721.893018</td>\n",
       "      <td>0.001439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.871100</td>\n",
       "      <td>3879.347831</td>\n",
       "      <td>0.001500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.2</td>\n",
       "      <td>13.671670</td>\n",
       "      <td>4219.963001</td>\n",
       "      <td>0.001631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.216382</td>\n",
       "      <td>3264.525349</td>\n",
       "      <td>0.001262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>718</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12.909529</td>\n",
       "      <td>4452.870790</td>\n",
       "      <td>0.001721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>719</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.899220</td>\n",
       "      <td>3996.445507</td>\n",
       "      <td>0.001545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.4</td>\n",
       "      <td>12.562956</td>\n",
       "      <td>2008.355425</td>\n",
       "      <td>0.000776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>11.884489</td>\n",
       "      <td>4590.060261</td>\n",
       "      <td>0.001775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>722</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.2</td>\n",
       "      <td>12.429216</td>\n",
       "      <td>5904.077240</td>\n",
       "      <td>0.002283</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>657 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Naturalgas  Oven  Refrigerator  Blender   age  own_status  Stereo  \\\n",
       "0           1.0   2.0           1.0      1.0  44.0           0     1.0   \n",
       "1           1.0   2.0           1.0      1.0  70.0           0     1.0   \n",
       "2           1.0   2.0           1.0      2.0  24.0           0     2.0   \n",
       "3           1.0   1.0           1.0      1.0  27.0           1     2.0   \n",
       "4           1.0   2.0           1.0      1.0  32.0           0     1.0   \n",
       "..          ...   ...           ...      ...   ...         ...     ...   \n",
       "718         1.0   2.0           1.0      1.0  48.0           0     2.0   \n",
       "719         1.0   2.0           1.0      1.0  51.0           0     2.0   \n",
       "720         1.0   1.0           1.0      1.0  40.0           0     2.0   \n",
       "721         1.0   2.0           1.0      1.0  36.0           0     1.0   \n",
       "722         1.0   2.0           1.0      1.0  30.0           0     2.0   \n",
       "\n",
       "     level_educ  Water_heater  Washing  tvservice  Sanserv2  Microwave  \\\n",
       "0           6.0           1.0      1.0        1.0       1.0        2.0   \n",
       "1           3.0           2.0      1.0        2.0       1.0        2.0   \n",
       "2           5.0           1.0      2.0        1.0       1.0        1.0   \n",
       "3           6.0           1.0      1.0        1.0       1.0        1.0   \n",
       "4           5.0           2.0      2.0        2.0       1.0        2.0   \n",
       "..          ...           ...      ...        ...       ...        ...   \n",
       "718         5.0           2.0      1.0        1.0       1.0        2.0   \n",
       "719         4.0           1.0      1.0        1.0       1.0        2.0   \n",
       "720         5.0           1.0      1.0        1.0       1.0        2.0   \n",
       "721         5.0           2.0      1.0        1.0       1.0        1.0   \n",
       "722         6.0           1.0      1.0        1.0       1.0        2.0   \n",
       "\n",
       "     ColorTV  marital_status  Phone_service  gender  Internet_service  \\\n",
       "0        1.0             3.0            2.0     2.0               1.0   \n",
       "1        1.0             1.0            2.0     2.0               2.0   \n",
       "2        1.0             2.0            2.0     1.0               1.0   \n",
       "3        1.0             1.0            2.0     1.0               1.0   \n",
       "4        1.0             2.0            1.0     2.0               1.0   \n",
       "..       ...             ...            ...     ...               ...   \n",
       "718      1.0             1.0            2.0     2.0               1.0   \n",
       "719      1.0             4.0            2.0     1.0               1.0   \n",
       "720      1.0             2.0            2.0     1.0               1.0   \n",
       "721      1.0             2.0            2.0     1.0               1.0   \n",
       "722      1.0             2.0            1.0     1.0               2.0   \n",
       "\n",
       "     Utilrank  Watserv  Numrooms  Numroomsleep  log_imputed_rent_uc  \\\n",
       "0           3      1.0  0.428571           0.4            12.899220   \n",
       "1           1      1.0  0.142857           0.0            12.670429   \n",
       "2           1      1.0  0.000000           0.0            12.871100   \n",
       "3           3      1.0  0.428571           0.2            13.671670   \n",
       "4           1      1.0  0.142857           0.0            12.216382   \n",
       "..        ...      ...       ...           ...                  ...   \n",
       "718         2      1.0  0.285714           0.2            12.909529   \n",
       "719         3      1.0  0.000000           0.0            12.899220   \n",
       "720         2      1.0  0.428571           0.4            12.562956   \n",
       "721         2      1.0  0.285714           0.2            11.884489   \n",
       "722         3      1.0  0.285714           0.2            12.429216   \n",
       "\n",
       "      fex_c_2011  fex_c_2011_ratio  \n",
       "0    2746.535202          0.001062  \n",
       "1    3721.893018          0.001439  \n",
       "2    3879.347831          0.001500  \n",
       "3    4219.963001          0.001631  \n",
       "4    3264.525349          0.001262  \n",
       "..           ...               ...  \n",
       "718  4452.870790          0.001721  \n",
       "719  3996.445507          0.001545  \n",
       "720  2008.355425          0.000776  \n",
       "721  4590.060261          0.001775  \n",
       "722  5904.077240          0.002283  \n",
       "\n",
       "[657 rows x 25 columns]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_bogota_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "1739b700-a7aa-4273-b472-9f01960310af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "On utilise un Weighted OLS avec les poids de sondage, car l'échantillon est petit (autour de 700 observations). \n",
       "Petite remarque : on utilise ici les poids de sondage pour notre regression car l'echantillon est petit et les regressions ponderees permettent de recouvrir des estimateurs convergents. Cependant, ils sont moins efficaces. Comme nous avions un echantillon de bonne taille dans les precedentes regressions, nous avons privilégié l'efficacité sur la consistence.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "markdown = \"\"\"\n",
    "On utilise un Weighted OLS avec les poids de sondage, car l'échantillon est petit (autour de 700 observations). \n",
    "Petite remarque : on utilise ici les poids de sondage pour notre regression car l'echantillon est petit et les regressions ponderees permettent de recouvrir des estimateurs convergents. Cependant, ils sont moins efficaces. Comme nous avions un echantillon de bonne taille dans les precedentes regressions, nous avons privilégié l'efficacité sur la consistence.\n",
    "\"\"\"\n",
    "display(Markdown(markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "3117f7c4-6303-495f-a4fa-5cff0f84b067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                 <th>OLS</th>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Numrooms</th>                  <td>1.0502***</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.1828)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                        <td>0.0012</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0016)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>                     <td>-0.0474</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0389)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>13.5472***</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.3022)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(own_status)[T.1]</th>         <td>0.0335</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0419)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(level_educ)[T.3.0]</th>       <td>-0.0815</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.1706)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(level_educ)[T.4.0]</th>       <td>-0.0473</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.1771)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(level_educ)[T.5.0]</th>       <td>-0.0881</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.1733)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(level_educ)[T.6.0]</th>       <td>0.0608</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.1773)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(marital_status)[T.2.0]</th> <td>-0.2228***</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0531)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(marital_status)[T.3.0]</th> <td>-0.2802***</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0589)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(marital_status)[T.4.0]</th>   <td>-0.0671</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0578)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(marital_status)[T.5.0]</th>   <td>-0.0022</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0822)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Utilrank)[T.2]</th>          <td>0.1357**</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0558)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Utilrank)[T.3]</th>          <td>0.3903***</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0611)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Utilrank)[T.4]</th>          <td>0.9492***</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0887)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Utilrank)[T.5]</th>          <td>1.5200***</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.1726)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Utilrank)[T.6]</th>          <td>1.9394***</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.1366)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Naturalgas</th>                 <td>-0.0829</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.1010)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Oven</th>                      <td>-0.0852*</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0448)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Refrigerator</th>              <td>-0.1680**</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0685)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blender</th>                    <td>0.0261</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0666)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Stereo</th>                     <td>-0.0085</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0379)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Water_heater</th>              <td>-0.0971**</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0402)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Washing</th>                    <td>-0.0547</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0536)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tvservice</th>                  <td>-0.0355</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0447)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sanserv2</th>                 <td>-0.2490***</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0830)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Microwave</th>                  <td>-0.0610</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0461)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ColorTV</th>                    <td>0.1194</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0866)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Numroomsleep</th>             <td>-0.7848***</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.1478)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Phone_service</th>              <td>-0.0125</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0413)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Internet_service</th>           <td>0.0308</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0469)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Watserv</th>                   <td>-0.0944*</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th></th>                          <td>(0.0515)</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>R-squared</th>                  <td>0.6391</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>R-squared Adj.</th>             <td>0.6206</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>R-squared</th>                   <td>0.639</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations</th>             <td>657</td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>F-statistic</th>                <td>34.531</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob (F-statistic)</th>         <td>0.0000</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Robust Covariance</th>         <td>nonrobust</td>\n",
       "</tr>\n",
       "</table><br/>\n",
       "Standard errors in parentheses.<br/>\n",
       "* p<.1, ** p<.05, ***p<.01"
      ],
      "text/latex": [
       "\\begin{table}\n",
       "\\caption{}\n",
       "\\label{}\n",
       "\\begin{center}\n",
       "\\begin{tabular}{ll}\n",
       "\\hline\n",
       "                          & OLS         \\\\\n",
       "\\hline\n",
       "Numrooms                  & 1.0502***   \\\\\n",
       "                          & (0.1828)    \\\\\n",
       "age                       & 0.0012      \\\\\n",
       "                          & (0.0016)    \\\\\n",
       "gender                    & -0.0474     \\\\\n",
       "                          & (0.0389)    \\\\\n",
       "Intercept                 & 13.5472***  \\\\\n",
       "                          & (0.3022)    \\\\\n",
       "C(own\\_status)[T.1]       & 0.0335      \\\\\n",
       "                          & (0.0419)    \\\\\n",
       "C(level\\_educ)[T.3.0]     & -0.0815     \\\\\n",
       "                          & (0.1706)    \\\\\n",
       "C(level\\_educ)[T.4.0]     & -0.0473     \\\\\n",
       "                          & (0.1771)    \\\\\n",
       "C(level\\_educ)[T.5.0]     & -0.0881     \\\\\n",
       "                          & (0.1733)    \\\\\n",
       "C(level\\_educ)[T.6.0]     & 0.0608      \\\\\n",
       "                          & (0.1773)    \\\\\n",
       "C(marital\\_status)[T.2.0] & -0.2228***  \\\\\n",
       "                          & (0.0531)    \\\\\n",
       "C(marital\\_status)[T.3.0] & -0.2802***  \\\\\n",
       "                          & (0.0589)    \\\\\n",
       "C(marital\\_status)[T.4.0] & -0.0671     \\\\\n",
       "                          & (0.0578)    \\\\\n",
       "C(marital\\_status)[T.5.0] & -0.0022     \\\\\n",
       "                          & (0.0822)    \\\\\n",
       "C(Utilrank)[T.2]          & 0.1357**    \\\\\n",
       "                          & (0.0558)    \\\\\n",
       "C(Utilrank)[T.3]          & 0.3903***   \\\\\n",
       "                          & (0.0611)    \\\\\n",
       "C(Utilrank)[T.4]          & 0.9492***   \\\\\n",
       "                          & (0.0887)    \\\\\n",
       "C(Utilrank)[T.5]          & 1.5200***   \\\\\n",
       "                          & (0.1726)    \\\\\n",
       "C(Utilrank)[T.6]          & 1.9394***   \\\\\n",
       "                          & (0.1366)    \\\\\n",
       "Naturalgas                & -0.0829     \\\\\n",
       "                          & (0.1010)    \\\\\n",
       "Oven                      & -0.0852*    \\\\\n",
       "                          & (0.0448)    \\\\\n",
       "Refrigerator              & -0.1680**   \\\\\n",
       "                          & (0.0685)    \\\\\n",
       "Blender                   & 0.0261      \\\\\n",
       "                          & (0.0666)    \\\\\n",
       "Stereo                    & -0.0085     \\\\\n",
       "                          & (0.0379)    \\\\\n",
       "Water\\_heater             & -0.0971**   \\\\\n",
       "                          & (0.0402)    \\\\\n",
       "Washing                   & -0.0547     \\\\\n",
       "                          & (0.0536)    \\\\\n",
       "tvservice                 & -0.0355     \\\\\n",
       "                          & (0.0447)    \\\\\n",
       "Sanserv2                  & -0.2490***  \\\\\n",
       "                          & (0.0830)    \\\\\n",
       "Microwave                 & -0.0610     \\\\\n",
       "                          & (0.0461)    \\\\\n",
       "ColorTV                   & 0.1194      \\\\\n",
       "                          & (0.0866)    \\\\\n",
       "Numroomsleep              & -0.7848***  \\\\\n",
       "                          & (0.1478)    \\\\\n",
       "Phone\\_service            & -0.0125     \\\\\n",
       "                          & (0.0413)    \\\\\n",
       "Internet\\_service         & 0.0308      \\\\\n",
       "                          & (0.0469)    \\\\\n",
       "Watserv                   & -0.0944*    \\\\\n",
       "                          & (0.0515)    \\\\\n",
       "R-squared                 & 0.6391      \\\\\n",
       "R-squared Adj.            & 0.6206      \\\\\n",
       "R-squared                 & 0.639       \\\\\n",
       "No. Observations          & 657         \\\\\n",
       "F-statistic               & 34.531      \\\\\n",
       "Prob (F-statistic)        & 0.0000      \\\\\n",
       "Robust Covariance         & nonrobust   \\\\\n",
       "\\hline\n",
       "\\end{tabular}\n",
       "\\end{center}\n",
       "\\end{table}\n",
       "\\bigskip\n",
       "Standard errors in parentheses. \\newline \n",
       "* p<.1, ** p<.05, ***p<.01"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "\n",
       "===================================\n",
       "                            OLS    \n",
       "-----------------------------------\n",
       "Numrooms                 1.0502*** \n",
       "                         (0.1828)  \n",
       "age                      0.0012    \n",
       "                         (0.0016)  \n",
       "gender                   -0.0474   \n",
       "                         (0.0389)  \n",
       "Intercept                13.5472***\n",
       "                         (0.3022)  \n",
       "C(own_status)[T.1]       0.0335    \n",
       "                         (0.0419)  \n",
       "C(level_educ)[T.3.0]     -0.0815   \n",
       "                         (0.1706)  \n",
       "C(level_educ)[T.4.0]     -0.0473   \n",
       "                         (0.1771)  \n",
       "C(level_educ)[T.5.0]     -0.0881   \n",
       "                         (0.1733)  \n",
       "C(level_educ)[T.6.0]     0.0608    \n",
       "                         (0.1773)  \n",
       "C(marital_status)[T.2.0] -0.2228***\n",
       "                         (0.0531)  \n",
       "C(marital_status)[T.3.0] -0.2802***\n",
       "                         (0.0589)  \n",
       "C(marital_status)[T.4.0] -0.0671   \n",
       "                         (0.0578)  \n",
       "C(marital_status)[T.5.0] -0.0022   \n",
       "                         (0.0822)  \n",
       "C(Utilrank)[T.2]         0.1357**  \n",
       "                         (0.0558)  \n",
       "C(Utilrank)[T.3]         0.3903*** \n",
       "                         (0.0611)  \n",
       "C(Utilrank)[T.4]         0.9492*** \n",
       "                         (0.0887)  \n",
       "C(Utilrank)[T.5]         1.5200*** \n",
       "                         (0.1726)  \n",
       "C(Utilrank)[T.6]         1.9394*** \n",
       "                         (0.1366)  \n",
       "Naturalgas               -0.0829   \n",
       "                         (0.1010)  \n",
       "Oven                     -0.0852*  \n",
       "                         (0.0448)  \n",
       "Refrigerator             -0.1680** \n",
       "                         (0.0685)  \n",
       "Blender                  0.0261    \n",
       "                         (0.0666)  \n",
       "Stereo                   -0.0085   \n",
       "                         (0.0379)  \n",
       "Water_heater             -0.0971** \n",
       "                         (0.0402)  \n",
       "Washing                  -0.0547   \n",
       "                         (0.0536)  \n",
       "tvservice                -0.0355   \n",
       "                         (0.0447)  \n",
       "Sanserv2                 -0.2490***\n",
       "                         (0.0830)  \n",
       "Microwave                -0.0610   \n",
       "                         (0.0461)  \n",
       "ColorTV                  0.1194    \n",
       "                         (0.0866)  \n",
       "Numroomsleep             -0.7848***\n",
       "                         (0.1478)  \n",
       "Phone_service            -0.0125   \n",
       "                         (0.0413)  \n",
       "Internet_service         0.0308    \n",
       "                         (0.0469)  \n",
       "Watserv                  -0.0944*  \n",
       "                         (0.0515)  \n",
       "R-squared                0.6391    \n",
       "R-squared Adj.           0.6206    \n",
       "R-squared                0.639     \n",
       "No. Observations         657       \n",
       "F-statistic              34.531    \n",
       "Prob (F-statistic)       0.0000    \n",
       "Robust Covariance        nonrobust \n",
       "===================================\n",
       "Standard errors in parentheses.\n",
       "* p<.1, ** p<.05, ***p<.01\n",
       "\"\"\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from statsmodels.iolib.summary2 import summary_col\n",
    "\n",
    "#weighted ols \n",
    "\n",
    "mod = smf.wls(formula='log_imputed_rent_uc ~ Naturalgas + Oven + Refrigerator + Blender + age + C(own_status) + Stereo + C(level_educ) + Water_heater + Washing + tvservice + Sanserv2 + Microwave + Numrooms + ColorTV + C(marital_status) + Numroomsleep + Phone_service + gender + Internet_service + C(Utilrank) + Watserv', data=data_bogota_reg,weights=data_bogota_reg['fex_c_2011_ratio'])\n",
    "res = mod.fit()\n",
    "summary_table = summary_col([res], stars=True, float_format='%0.4f', model_names=['OLS'], info_dict={'R-squared': lambda x: f\"{x.rsquared:0.3f}\", 'No. Observations': lambda x: f\"{int(x.nobs)}\", 'F-statistic': lambda x: f\"{x.fvalue:0.3f}\", 'Prob (F-statistic)': lambda x: f\"{x.f_pvalue:0.4f}\", 'Robust Covariance': lambda x: f\"{x.cov_type}\"}, regressor_order=['C(territory)[T.1]','Numrooms', 'C(Utilrank)[T.1]', 'level_educ', 'age', 'marital_status', 'gender'])\n",
    "display(summary_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "d9ecfb79-79b5-4192-b3cc-59c00670717f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>VIF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intercept</td>\n",
       "      <td>333.754812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C(own_status)[T.1]</td>\n",
       "      <td>1.511837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C(level_educ)[T.3.0]</td>\n",
       "      <td>17.575887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C(level_educ)[T.4.0]</td>\n",
       "      <td>9.249446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C(level_educ)[T.5.0]</td>\n",
       "      <td>24.479261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C(level_educ)[T.6.0]</td>\n",
       "      <td>24.451067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C(marital_status)[T.2.0]</td>\n",
       "      <td>2.216881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C(marital_status)[T.3.0]</td>\n",
       "      <td>2.087310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C(marital_status)[T.4.0]</td>\n",
       "      <td>1.752289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C(marital_status)[T.5.0]</td>\n",
       "      <td>1.587332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C(Utilrank)[T.2]</td>\n",
       "      <td>2.829497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C(Utilrank)[T.3]</td>\n",
       "      <td>3.133500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C(Utilrank)[T.4]</td>\n",
       "      <td>2.188545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C(Utilrank)[T.5]</td>\n",
       "      <td>1.263616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C(Utilrank)[T.6]</td>\n",
       "      <td>1.325715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Naturalgas</td>\n",
       "      <td>1.176100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Oven</td>\n",
       "      <td>1.440191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Refrigerator</td>\n",
       "      <td>1.765266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Blender</td>\n",
       "      <td>1.602709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>age</td>\n",
       "      <td>2.169667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Stereo</td>\n",
       "      <td>1.227670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Water_heater</td>\n",
       "      <td>1.429505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Washing</td>\n",
       "      <td>1.728513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>tvservice</td>\n",
       "      <td>1.328021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sanserv2</td>\n",
       "      <td>1.177801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Microwave</td>\n",
       "      <td>1.533300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Numrooms</td>\n",
       "      <td>2.930889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>ColorTV</td>\n",
       "      <td>1.172823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Numroomsleep</td>\n",
       "      <td>2.014326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Phone_service</td>\n",
       "      <td>1.419107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>gender</td>\n",
       "      <td>1.381078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Internet_service</td>\n",
       "      <td>1.544951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Watserv</td>\n",
       "      <td>1.051220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Variable         VIF\n",
       "0                  Intercept  333.754812\n",
       "1         C(own_status)[T.1]    1.511837\n",
       "2       C(level_educ)[T.3.0]   17.575887\n",
       "3       C(level_educ)[T.4.0]    9.249446\n",
       "4       C(level_educ)[T.5.0]   24.479261\n",
       "5       C(level_educ)[T.6.0]   24.451067\n",
       "6   C(marital_status)[T.2.0]    2.216881\n",
       "7   C(marital_status)[T.3.0]    2.087310\n",
       "8   C(marital_status)[T.4.0]    1.752289\n",
       "9   C(marital_status)[T.5.0]    1.587332\n",
       "10          C(Utilrank)[T.2]    2.829497\n",
       "11          C(Utilrank)[T.3]    3.133500\n",
       "12          C(Utilrank)[T.4]    2.188545\n",
       "13          C(Utilrank)[T.5]    1.263616\n",
       "14          C(Utilrank)[T.6]    1.325715\n",
       "15                Naturalgas    1.176100\n",
       "16                      Oven    1.440191\n",
       "17              Refrigerator    1.765266\n",
       "18                   Blender    1.602709\n",
       "19                       age    2.169667\n",
       "20                    Stereo    1.227670\n",
       "21              Water_heater    1.429505\n",
       "22                   Washing    1.728513\n",
       "23                 tvservice    1.328021\n",
       "24                  Sanserv2    1.177801\n",
       "25                 Microwave    1.533300\n",
       "26                  Numrooms    2.930889\n",
       "27                   ColorTV    1.172823\n",
       "28              Numroomsleep    2.014326\n",
       "29             Phone_service    1.419107\n",
       "30                    gender    1.381078\n",
       "31          Internet_service    1.544951\n",
       "32                   Watserv    1.051220"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = res.model.exog\n",
    "vif = pd.DataFrame()\n",
    "vif[\"Variable\"] = res.params.index\n",
    "vif[\"VIF\"] = [variance_inflation_factor(X, i) for i in range(X.shape[1])]\n",
    "vif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "387a7a0a-1915-4043-8155-2e44a4d789ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>level_educ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.402661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>level_educ</th>\n",
       "      <td>-0.402661</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 age  level_educ\n",
       "age         1.000000   -0.402661\n",
       "level_educ -0.402661    1.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "\n",
       "level_educ est tres correlee à level_educ\n",
       "mais c'est pas grave si ces deux variables ne sont pas significatives : ce sont des controles sociodemographiques\n",
       "elles sont tres correlees entre elles // a part ces variables, rien a signaler \n",
       "\n",
       "Revenons aux coefficients et aux p-valeurs trouvés : \n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "corr = bogota[['age','level_educ']].corr()\n",
    "display(corr) \n",
    "\n",
    "markdown = \"\"\"\n",
    "La variable level_educ est tres correlee à level_educ mais c'est pas grave si ces deux variables ne sont pas significatives : ce sont des controles sociodemographiques\n",
    "elles sont tres correlees entre elles // a part ces variables, rien a signaler \n",
    "\n",
    "Revenons aux coefficients et aux p-valeurs trouvés de la regression pondérée des probabilités d'inclusion des individus: \n",
    "\"\"\"\n",
    "display(Markdown(markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "33ba0255-56f3-4e15-aa89-b0560f1a809c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "              <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                <td>   13.5472</td> <td>    0.302</td> <td>   44.832</td> <td> 0.000</td> <td>   12.954</td> <td>   14.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(own_status)[T.1]</th>       <td>    0.0335</td> <td>    0.042</td> <td>    0.801</td> <td> 0.424</td> <td>   -0.049</td> <td>    0.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(level_educ)[T.3.0]</th>     <td>   -0.0815</td> <td>    0.171</td> <td>   -0.478</td> <td> 0.633</td> <td>   -0.416</td> <td>    0.253</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(level_educ)[T.4.0]</th>     <td>   -0.0473</td> <td>    0.177</td> <td>   -0.267</td> <td> 0.790</td> <td>   -0.395</td> <td>    0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(level_educ)[T.5.0]</th>     <td>   -0.0881</td> <td>    0.173</td> <td>   -0.509</td> <td> 0.611</td> <td>   -0.428</td> <td>    0.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(level_educ)[T.6.0]</th>     <td>    0.0608</td> <td>    0.177</td> <td>    0.343</td> <td> 0.732</td> <td>   -0.287</td> <td>    0.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(marital_status)[T.2.0]</th> <td>   -0.2228</td> <td>    0.053</td> <td>   -4.195</td> <td> 0.000</td> <td>   -0.327</td> <td>   -0.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(marital_status)[T.3.0]</th> <td>   -0.2802</td> <td>    0.059</td> <td>   -4.756</td> <td> 0.000</td> <td>   -0.396</td> <td>   -0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(marital_status)[T.4.0]</th> <td>   -0.0671</td> <td>    0.058</td> <td>   -1.160</td> <td> 0.246</td> <td>   -0.181</td> <td>    0.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(marital_status)[T.5.0]</th> <td>   -0.0022</td> <td>    0.082</td> <td>   -0.027</td> <td> 0.979</td> <td>   -0.164</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Utilrank)[T.2]</th>         <td>    0.1357</td> <td>    0.056</td> <td>    2.432</td> <td> 0.015</td> <td>    0.026</td> <td>    0.245</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Utilrank)[T.3]</th>         <td>    0.3903</td> <td>    0.061</td> <td>    6.387</td> <td> 0.000</td> <td>    0.270</td> <td>    0.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Utilrank)[T.4]</th>         <td>    0.9492</td> <td>    0.089</td> <td>   10.698</td> <td> 0.000</td> <td>    0.775</td> <td>    1.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Utilrank)[T.5]</th>         <td>    1.5200</td> <td>    0.173</td> <td>    8.804</td> <td> 0.000</td> <td>    1.181</td> <td>    1.859</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Utilrank)[T.6]</th>         <td>    1.9394</td> <td>    0.137</td> <td>   14.200</td> <td> 0.000</td> <td>    1.671</td> <td>    2.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Naturalgas</th>               <td>   -0.0829</td> <td>    0.101</td> <td>   -0.821</td> <td> 0.412</td> <td>   -0.281</td> <td>    0.115</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Oven</th>                     <td>   -0.0852</td> <td>    0.045</td> <td>   -1.905</td> <td> 0.057</td> <td>   -0.173</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Refrigerator</th>             <td>   -0.1680</td> <td>    0.069</td> <td>   -2.452</td> <td> 0.014</td> <td>   -0.303</td> <td>   -0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Blender</th>                  <td>    0.0261</td> <td>    0.067</td> <td>    0.391</td> <td> 0.696</td> <td>   -0.105</td> <td>    0.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>                      <td>    0.0012</td> <td>    0.002</td> <td>    0.738</td> <td> 0.461</td> <td>   -0.002</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Stereo</th>                   <td>   -0.0085</td> <td>    0.038</td> <td>   -0.225</td> <td> 0.822</td> <td>   -0.083</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Water_heater</th>             <td>   -0.0971</td> <td>    0.040</td> <td>   -2.416</td> <td> 0.016</td> <td>   -0.176</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Washing</th>                  <td>   -0.0547</td> <td>    0.054</td> <td>   -1.021</td> <td> 0.308</td> <td>   -0.160</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tvservice</th>                <td>   -0.0355</td> <td>    0.045</td> <td>   -0.793</td> <td> 0.428</td> <td>   -0.123</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Sanserv2</th>                 <td>   -0.2490</td> <td>    0.083</td> <td>   -3.000</td> <td> 0.003</td> <td>   -0.412</td> <td>   -0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Microwave</th>                <td>   -0.0610</td> <td>    0.046</td> <td>   -1.324</td> <td> 0.186</td> <td>   -0.152</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Numrooms</th>                 <td>    1.0502</td> <td>    0.183</td> <td>    5.746</td> <td> 0.000</td> <td>    0.691</td> <td>    1.409</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ColorTV</th>                  <td>    0.1194</td> <td>    0.087</td> <td>    1.379</td> <td> 0.168</td> <td>   -0.051</td> <td>    0.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Numroomsleep</th>             <td>   -0.7848</td> <td>    0.148</td> <td>   -5.311</td> <td> 0.000</td> <td>   -1.075</td> <td>   -0.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Phone_service</th>            <td>   -0.0125</td> <td>    0.041</td> <td>   -0.302</td> <td> 0.763</td> <td>   -0.094</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>gender</th>                   <td>   -0.0474</td> <td>    0.039</td> <td>   -1.217</td> <td> 0.224</td> <td>   -0.124</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Internet_service</th>         <td>    0.0308</td> <td>    0.047</td> <td>    0.657</td> <td> 0.512</td> <td>   -0.061</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Watserv</th>                  <td>   -0.0944</td> <td>    0.051</td> <td>   -1.833</td> <td> 0.067</td> <td>   -0.195</td> <td>    0.007</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lcccccc}\n",
       "\\toprule\n",
       "                                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                 &      13.5472  &        0.302     &    44.832  &         0.000        &       12.954    &       14.141     \\\\\n",
       "\\textbf{C(own\\_status)[T.1]}       &       0.0335  &        0.042     &     0.801  &         0.424        &       -0.049    &        0.116     \\\\\n",
       "\\textbf{C(level\\_educ)[T.3.0]}     &      -0.0815  &        0.171     &    -0.478  &         0.633        &       -0.416    &        0.253     \\\\\n",
       "\\textbf{C(level\\_educ)[T.4.0]}     &      -0.0473  &        0.177     &    -0.267  &         0.790        &       -0.395    &        0.300     \\\\\n",
       "\\textbf{C(level\\_educ)[T.5.0]}     &      -0.0881  &        0.173     &    -0.509  &         0.611        &       -0.428    &        0.252     \\\\\n",
       "\\textbf{C(level\\_educ)[T.6.0]}     &       0.0608  &        0.177     &     0.343  &         0.732        &       -0.287    &        0.409     \\\\\n",
       "\\textbf{C(marital\\_status)[T.2.0]} &      -0.2228  &        0.053     &    -4.195  &         0.000        &       -0.327    &       -0.119     \\\\\n",
       "\\textbf{C(marital\\_status)[T.3.0]} &      -0.2802  &        0.059     &    -4.756  &         0.000        &       -0.396    &       -0.164     \\\\\n",
       "\\textbf{C(marital\\_status)[T.4.0]} &      -0.0671  &        0.058     &    -1.160  &         0.246        &       -0.181    &        0.046     \\\\\n",
       "\\textbf{C(marital\\_status)[T.5.0]} &      -0.0022  &        0.082     &    -0.027  &         0.979        &       -0.164    &        0.159     \\\\\n",
       "\\textbf{C(Utilrank)[T.2]}          &       0.1357  &        0.056     &     2.432  &         0.015        &        0.026    &        0.245     \\\\\n",
       "\\textbf{C(Utilrank)[T.3]}          &       0.3903  &        0.061     &     6.387  &         0.000        &        0.270    &        0.510     \\\\\n",
       "\\textbf{C(Utilrank)[T.4]}          &       0.9492  &        0.089     &    10.698  &         0.000        &        0.775    &        1.123     \\\\\n",
       "\\textbf{C(Utilrank)[T.5]}          &       1.5200  &        0.173     &     8.804  &         0.000        &        1.181    &        1.859     \\\\\n",
       "\\textbf{C(Utilrank)[T.6]}          &       1.9394  &        0.137     &    14.200  &         0.000        &        1.671    &        2.208     \\\\\n",
       "\\textbf{Naturalgas}                &      -0.0829  &        0.101     &    -0.821  &         0.412        &       -0.281    &        0.115     \\\\\n",
       "\\textbf{Oven}                      &      -0.0852  &        0.045     &    -1.905  &         0.057        &       -0.173    &        0.003     \\\\\n",
       "\\textbf{Refrigerator}              &      -0.1680  &        0.069     &    -2.452  &         0.014        &       -0.303    &       -0.033     \\\\\n",
       "\\textbf{Blender}                   &       0.0261  &        0.067     &     0.391  &         0.696        &       -0.105    &        0.157     \\\\\n",
       "\\textbf{age}                       &       0.0012  &        0.002     &     0.738  &         0.461        &       -0.002    &        0.004     \\\\\n",
       "\\textbf{Stereo}                    &      -0.0085  &        0.038     &    -0.225  &         0.822        &       -0.083    &        0.066     \\\\\n",
       "\\textbf{Water\\_heater}             &      -0.0971  &        0.040     &    -2.416  &         0.016        &       -0.176    &       -0.018     \\\\\n",
       "\\textbf{Washing}                   &      -0.0547  &        0.054     &    -1.021  &         0.308        &       -0.160    &        0.051     \\\\\n",
       "\\textbf{tvservice}                 &      -0.0355  &        0.045     &    -0.793  &         0.428        &       -0.123    &        0.052     \\\\\n",
       "\\textbf{Sanserv2}                  &      -0.2490  &        0.083     &    -3.000  &         0.003        &       -0.412    &       -0.086     \\\\\n",
       "\\textbf{Microwave}                 &      -0.0610  &        0.046     &    -1.324  &         0.186        &       -0.152    &        0.029     \\\\\n",
       "\\textbf{Numrooms}                  &       1.0502  &        0.183     &     5.746  &         0.000        &        0.691    &        1.409     \\\\\n",
       "\\textbf{ColorTV}                   &       0.1194  &        0.087     &     1.379  &         0.168        &       -0.051    &        0.289     \\\\\n",
       "\\textbf{Numroomsleep}              &      -0.7848  &        0.148     &    -5.311  &         0.000        &       -1.075    &       -0.495     \\\\\n",
       "\\textbf{Phone\\_service}            &      -0.0125  &        0.041     &    -0.302  &         0.763        &       -0.094    &        0.069     \\\\\n",
       "\\textbf{gender}                    &      -0.0474  &        0.039     &    -1.217  &         0.224        &       -0.124    &        0.029     \\\\\n",
       "\\textbf{Internet\\_service}         &       0.0308  &        0.047     &     0.657  &         0.512        &       -0.061    &        0.123     \\\\\n",
       "\\textbf{Watserv}                   &      -0.0944  &        0.051     &    -1.833  &         0.067        &       -0.195    &        0.007     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(res.summary().tables[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "b5c6912f-26fa-42f0-a0b0-7e4f0b94013b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "Tous les coefficients sauf ceux d'Utilrank, deux categories du statut marital, Numrooms et Numroomsleep sont significatifs à 0.1%. Il n'est pas grave que les coefficients des variables sociocategoriques et les amenités ne soient pas significatifs, car ils sont des variables qui contrôlent de ces caractéristiques.  \n",
       "\n",
       "Toutes les autres variables agissent comme des contrôles. Il est interessant de voir tout de même pour le statut marital (la reference de marital_status etant 1: celibataire), que un individu en couple (==2) ou marié (==3) ont un coût de logement plus faible, par unité de consommation - c'est cohérent à cause de la composition du ménage (deux individus en couple dépensent moins par tête en logement qu'une personne célibataire). Pour cette même variable catégorielle, on voit aussi qu'etre divorce (==5) ou veuf (==6) ne permet pas de conclure sur le coût de la vie selon ces catégories de populations.  Mais on peut dire que pour un veuf (==6) en moyenne, il n'y a pas de différence entre entre célibataire (==1, la référence) et etre veuf (==6, car la p-valeur est presque egale à 1, donc pas d'écarts par rapport à la catégorie de référence)  \n",
       "Cela nous conforte que les résultats de cette regression sont exploitables car cohérents. \n",
       "\n",
       "Donc la variable Utilrank isole à présent la richesse individuelle selon son habitation (interaction richesse x territoire). En effet, le rang d'utilités que paie un individu dépend du logement où il habite, chaque logement en Colombie est évalué et assigné un rang Utilrank ([(Medina, (2007), p.44)](https://www.jstor.org/stable/20060492): \"To improve the targeting of subsidies, by 1968 the Junta Nacional de Tar ifas (JNT), the Colombian institution in charge of determining public utility services rates and monitoring utilities' compliance with rates, introduced two features : \n",
       "new features to the targeting mechanisms: the definition of a basic consump tion level, which would have the higher subsidized rates, and a different IBP (Increasing block pricing) structure contingent on housing appraisal\") \n",
       "\n",
       "Ainsi, l'ajout d'amenités permet d'isoler la richesse individuelle selon le territoire, vu que le rang est détermine selon les caractéristiques (amenités) du logement. Donc la variable Utilrank peut expliquer la mixité spatiale observée ; elle dépend de où se situent les habitations à Utilrank élevées.\n",
       "Quant aux coefficients d'Utilrank, on voit que plus la catégorie Utilrank est elevée, et plus les dépenses en logement sont importantes. \n",
       "\n",
       "On serait tenté de dire que Bogota suit une structure monocentrique, si on s'en tient à l'hypothèse du gradient logement-distance : les individus plus riches peuvent consommer plus dans le poste de logement, et donc des logements plus en demande (Utilrank plus élevé). Mais on ne peut pas être sur de la répartition spatiale des logements plus en demande (répartition spatiale d'Utilrank). En effet, il faudrait approfondir avec des données communales, car la taille de Bogota demande une etude avec une echelle plus fine (plus de 10 fois la superficie de Paris et plus de 3 fois sa population).\n",
       "\n",
       "De plus, la variable Utilrank suit une distribution quasi-normale, donc il est aussi possible qu'Utilrank soit distribué spatialement de facon uniforme/aléatoire dans le département de Bogota, et ainsi, les coefficients d'Utilrank expliqueraient une répartition pluricentrique de la population à l'intérieur du territoire de Bogota : il y aurait plusieurs centres urbains où la demande / consommation en logement est plus élevée qu'en moyenne. Mais encore une fois, il faudrait étudier plus finement le territoire. C'est donc un début de réponse concernant la potentielle structure intra-territoriale du département de Bogota. Pour le reste du territoire, nos analyses soutiennent une organisation urbaine adoptant une structure monocentrique du gradient logement-transport.   \n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "markdown = \"\"\"\n",
    "Tous les coefficients sauf ceux d'Utilrank, deux categories du statut marital, Numrooms et Numroomsleep sont significatifs à 0.1%. Il n'est pas grave que les coefficients des variables sociocategoriques et les amenités ne soient pas significatifs, car ils sont des variables qui contrôlent de ces caractéristiques.  \n",
    "\n",
    "Toutes les autres variables agissent comme des contrôles. Il est interessant de voir tout de même pour le statut marital (la reference de marital_status etant 1: celibataire), que un individu en couple (==2) ou marié (==3) ont un coût de logement plus faible, par unité de consommation - c'est cohérent à cause de la composition du ménage (deux individus en couple dépensent moins par tête en logement qu'une personne célibataire). Pour cette même variable catégorielle, on voit aussi qu'etre divorce (==5) ou veuf (==6) ne permet pas de conclure sur le coût de la vie selon ces catégories de populations.  Mais on peut dire que pour un veuf (==6) en moyenne, il n'y a pas de différence entre entre célibataire (==1, la référence) et etre veuf (==6, car la p-valeur est presque egale à 1, donc pas d'écarts par rapport à la catégorie de référence)  \n",
    "Cela nous conforte que les résultats de cette regression sont exploitables car cohérents. \n",
    "\n",
    "Donc la variable Utilrank isole à présent la richesse individuelle selon son habitation (interaction richesse x territoire). En effet, le rang d'utilités que paie un individu dépend du logement où il habite, chaque logement en Colombie est évalué et assigné un rang Utilrank ([(Medina, (2007), p.44)](https://www.jstor.org/stable/20060492): \"To improve the targeting of subsidies, by 1968 the Junta Nacional de Tar ifas (JNT), the Colombian institution in charge of determining public utility services rates and monitoring utilities' compliance with rates, introduced two features : \n",
    "new features to the targeting mechanisms: the definition of a basic consump tion level, which would have the higher subsidized rates, and a different IBP (Increasing block pricing) structure contingent on housing appraisal\") \n",
    "\n",
    "Ainsi, l'ajout d'amenités permet d'isoler la richesse individuelle selon le territoire, vu que le rang est détermine selon les caractéristiques (amenités) du logement. Donc la variable Utilrank peut expliquer la mixité spatiale observée ; elle dépend de où se situent les habitations à Utilrank élevées.\n",
    "Quant aux coefficients d'Utilrank, on voit que plus la catégorie Utilrank est elevée, et plus les dépenses en logement sont importantes. \n",
    "\n",
    "On serait tenté de dire que Bogota suit une structure monocentrique, si on s'en tient à l'hypothèse du gradient logement-distance : les individus plus riches peuvent consommer plus dans le poste de logement, et donc des logements plus en demande (Utilrank plus élevé). Mais on ne peut pas être sur de la répartition spatiale des logements plus en demande (répartition spatiale d'Utilrank). En effet, il faudrait approfondir avec des données communales, car la taille de Bogota demande une etude avec une echelle plus fine (plus de 10 fois la superficie de Paris et plus de 3 fois sa population).\n",
    "\n",
    "De plus, la variable Utilrank suit une distribution quasi-normale, donc il est aussi possible qu'Utilrank soit distribué spatialement de facon uniforme/aléatoire dans le département de Bogota, et ainsi, les coefficients d'Utilrank expliqueraient une répartition pluricentrique de la population à l'intérieur du territoire de Bogota : il y aurait plusieurs centres urbains où la demande / consommation en logement est plus élevée qu'en moyenne. Mais encore une fois, il faudrait étudier plus finement le territoire. C'est donc un début de réponse concernant la potentielle structure intra-territoriale du département de Bogota. Pour le reste du territoire, nos analyses soutiennent une organisation urbaine adoptant une structure monocentrique du gradient logement-transport.   \n",
    "\n",
    "\"\"\"\n",
    "display(Markdown(markdown))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "6d6976dc-4d9d-41ab-85fd-25d1384ed3bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "\n",
    "data_bogota_reg[\"Utilrank_weights\"] = data_bogota_reg['Utilrank']*data_bogota_reg['fex_c_2011']\n",
    "\n",
    "# Plot histogram\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.histplot(data_bogota_reg[\"Utilrank_weights\"] , bins=20, kde=True, color='blue', edgecolor='black')\n",
    "plt.title('Répartition d\\'Utilrank à Bogota, avec poids d\\'inclusion, distribution quasi-normale')\n",
    "plt.xlabel('Utilrank')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4349baff-fe3b-48c6-84bd-8521478c0e8a",
   "metadata": {},
   "source": [
    "Bibliographie : \n",
    "\n",
    "[Medina et al. (2007) Stratification and Public Utility Services in Colombia: Subsidies to Households or Distortion of Housing Prices? Economía, Vol. 7, No. 2 (Spring, 2007), pp. 41-99](https://www.jstor.org/stable/20060492) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1de1c7e-f12e-4fbe-94e4-7f269dd090f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
